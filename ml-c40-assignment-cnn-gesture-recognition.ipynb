{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Gesture Recognition\nIn this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\n#from scipy.misc import imread, imresize\nimport cv2\nfrom PIL import Image\nfrom skimage import io \nimport skimage\nimport datetime\nimport os\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:29:12.777187Z","iopub.execute_input":"2022-12-07T11:29:12.777580Z","iopub.status.idle":"2022-12-07T11:29:12.787798Z","shell.execute_reply.started":"2022-12-07T11:29:12.777547Z","shell.execute_reply":"2022-12-07T11:29:12.786722Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"We set the random seed so that the results don't vary drastically.","metadata":{}},{"cell_type":"code","source":"np.random.seed(30)\nimport random as rn\nrn.seed(30)\nfrom keras import backend as K\nimport tensorflow as tf\ntf.random.set_seed(30)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:29:12.789945Z","iopub.execute_input":"2022-12-07T11:29:12.790516Z","iopub.status.idle":"2022-12-07T11:29:12.801231Z","shell.execute_reply.started":"2022-12-07T11:29:12.790473Z","shell.execute_reply":"2022-12-07T11:29:12.800071Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error.","metadata":{}},{"cell_type":"code","source":"train_doc = np.random.permutation(open('/kaggle/input/gesture-recognition-upgrad/Project_data/train.csv').readlines())\nval_doc = np.random.permutation(open('/kaggle/input/gesture-recognition-upgrad/Project_data/val.csv').readlines())\nbatch_size = 20#experiment with the batch size","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:29:12.821450Z","iopub.execute_input":"2022-12-07T11:29:12.821972Z","iopub.status.idle":"2022-12-07T11:29:12.833654Z","shell.execute_reply.started":"2022-12-07T11:29:12.821946Z","shell.execute_reply":"2022-12-07T11:29:12.832231Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"## Generator\nThis is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy.","metadata":{}},{"cell_type":"code","source":"def generator(source_path, folder_list, batch_size):\n    print( 'Source path = ', source_path, '; batch size =', batch_size)\n    img_idx = [1,3,4,5,7,8,9,10,12,14,15,16,18,20,22,24,26,28]#create a list of image numbers you want to use for a particular video\n    while True:\n        t = np.random.permutation(folder_list)\n        num_batches = int((len(t) / batch_size))# calculate the number of batches\n        for batch in range(num_batches): # we iterate over the number of batches\n            print('batch',batch)\n            batch_data = np.zeros((batch_size,18,120,120,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n            for folder in range(batch_size): # iterate over the batch_size\n                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n                    image = cv2.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item])\n                    #print( 'image shape = ', image.shape)\n                    image = cv2.resize(image,(120,120),fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n                    #crop the images and resize them. Note that the images are of 2 different shape \n                    #and the conv3D will throw error if the inputs in a batch have different shapes\n                    #print( 'image shape0 = ', image)\n                    batch_data[folder,idx,:,:,0] = (image[:,:,0] - np.percentile(image[:,:,0],5))/ (np.percentile(image[:,:,0],95) - np.percentile(image[:,:,0],5))#normalise and feed in the image\n                    batch_data[folder,idx,:,:,1] = (image[:,:,1] - np.percentile(image[:,:,1],5))/ (np.percentile(image[:,:,1],95) - np.percentile(image[:,:,1],5))#normalise and feed in the image\n                    batch_data[folder,idx,:,:,2] = (image[:,:,2] - np.percentile(image[:,:,2],5))/ (np.percentile(image[:,:,2],95) - np.percentile(image[:,:,2],5)) #normalise and feed in the image\n                    \n                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n        \n        if (len(t)%batch_size) != 0:\n            print('last batch',len(t)%batch_size)\n            print('num_batches',num_batches)\n            batch_data = np.zeros((len(t)%batch_size,18,120,120,3))\n            batch_labels = np.zeros((len(t)%batch_size,5))\n            for folder in range(len(t)%batch_size):\n                \n                imgs = os.listdir(source_path+'/'+ t[folder + ((num_batches-1)*batch_size)].split(';')[0])\n                for idx,item in enumerate(img_idx):\n                    image = cv2.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item])\n                    image = cv2.resize(image,(120,120),fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n\n                    batch_data[folder,idx,:,:,0] = (image[:,:,0] - np.percentile(image[:,:,0],5))/ (np.percentile(image[:,:,0],95) - np.percentile(image[:,:,0],5))#normalise and feed in the image\n                    batch_data[folder,idx,:,:,1] = (image[:,:,1] - np.percentile(image[:,:,1],5))/ (np.percentile(image[:,:,1],95) - np.percentile(image[:,:,1],5))#normalise and feed in the image\n                    batch_data[folder,idx,:,:,2] = (image[:,:,2] - np.percentile(image[:,:,2],5))/ (np.percentile(image[:,:,2],95) - np.percentile(image[:,:,2],5)) #normalise and feed in the image\n                batch_labels[folder, int(t[folder + ((num_batches-1)*batch_size)].strip().split(';')[2])] = 1\n            yield batch_data, batch_labels\n        # write the code for the remaining data points which are left after full batches\n","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:29:12.907979Z","iopub.execute_input":"2022-12-07T11:29:12.908263Z","iopub.status.idle":"2022-12-07T11:29:12.934133Z","shell.execute_reply.started":"2022-12-07T11:29:12.908237Z","shell.execute_reply":"2022-12-07T11:29:12.933057Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture.","metadata":{}},{"cell_type":"code","source":"curr_dt_time = datetime.datetime.now()\ntrain_path = '/kaggle/input/gesture-recognition-upgrad/Project_data/train'\nval_path = '/kaggle/input/gesture-recognition-upgrad/Project_data/val'\nnum_train_sequences = len(train_doc)\nprint('# training sequences =', num_train_sequences)\nnum_val_sequences = len(val_doc)\nprint('# validation sequences =', num_val_sequences)\nnum_epochs = 30 # choose the number of epochs\nprint ('# epochs =', num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:29:12.938366Z","iopub.execute_input":"2022-12-07T11:29:12.938949Z","iopub.status.idle":"2022-12-07T11:29:12.949252Z","shell.execute_reply.started":"2022-12-07T11:29:12.938915Z","shell.execute_reply":"2022-12-07T11:29:12.948194Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"# training sequences = 663\n# validation sequences = 100\n# epochs = 30\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model\nHere you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam.","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, GRU, Dropout, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\nfrom keras.layers.convolutional import Conv3D, MaxPooling3D\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras import optimizers\n\n\nmodel = Sequential()\nmodel.add(Conv3D(32, (3,3,3), strides=(1,1,1), padding='same', input_shape=(18,120,120,3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('elu'))\nmodel.add(MaxPooling3D(pool_size=(2,2,2), strides=(1,1,1)))\n\nmodel.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('elu'))\nmodel.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('elu'))\nmodel.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('elu'))\nmodel.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='elu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5, activation='softmax'))\n#write your model here","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:29:12.951467Z","iopub.execute_input":"2022-12-07T11:29:12.952048Z","iopub.status.idle":"2022-12-07T11:29:13.090097Z","shell.execute_reply.started":"2022-12-07T11:29:12.952012Z","shell.execute_reply":"2022-12-07T11:29:13.089095Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train.","metadata":{}},{"cell_type":"code","source":"optimiser = keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.7, nesterov=True)#write your optimizer\nmodel.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\nprint (model.summary())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-12-07T11:29:13.091654Z","iopub.execute_input":"2022-12-07T11:29:13.093137Z","iopub.status.idle":"2022-12-07T11:29:13.107922Z","shell.execute_reply.started":"2022-12-07T11:29:13.093100Z","shell.execute_reply":"2022-12-07T11:29:13.106886Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv3d_22 (Conv3D)           (None, 18, 120, 120, 32)  2624      \n_________________________________________________________________\nbatch_normalization_18 (Batc (None, 18, 120, 120, 32)  128       \n_________________________________________________________________\nactivation_22 (Activation)   (None, 18, 120, 120, 32)  0         \n_________________________________________________________________\nmax_pooling3d_22 (MaxPooling (None, 17, 119, 119, 32)  0         \n_________________________________________________________________\nconv3d_23 (Conv3D)           (None, 17, 119, 119, 64)  55360     \n_________________________________________________________________\nbatch_normalization_19 (Batc (None, 17, 119, 119, 64)  256       \n_________________________________________________________________\nactivation_23 (Activation)   (None, 17, 119, 119, 64)  0         \n_________________________________________________________________\nmax_pooling3d_23 (MaxPooling (None, 8, 59, 59, 64)     0         \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 8, 59, 59, 64)     0         \n_________________________________________________________________\nconv3d_24 (Conv3D)           (None, 8, 59, 59, 128)    221312    \n_________________________________________________________________\nbatch_normalization_20 (Batc (None, 8, 59, 59, 128)    512       \n_________________________________________________________________\nactivation_24 (Activation)   (None, 8, 59, 59, 128)    0         \n_________________________________________________________________\nmax_pooling3d_24 (MaxPooling (None, 4, 29, 29, 128)    0         \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 4, 29, 29, 128)    0         \n_________________________________________________________________\nconv3d_25 (Conv3D)           (None, 4, 29, 29, 128)    442496    \n_________________________________________________________________\nbatch_normalization_21 (Batc (None, 4, 29, 29, 128)    512       \n_________________________________________________________________\nactivation_25 (Activation)   (None, 4, 29, 29, 128)    0         \n_________________________________________________________________\nmax_pooling3d_25 (MaxPooling (None, 2, 14, 14, 128)    0         \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 50176)             0         \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 50176)             0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 256)               12845312  \n_________________________________________________________________\ndropout_15 (Dropout)         (None, 256)               0         \n_________________________________________________________________\ndense_11 (Dense)             (None, 5)                 1285      \n=================================================================\nTotal params: 13,569,797\nTrainable params: 13,569,093\nNon-trainable params: 704\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.","metadata":{}},{"cell_type":"code","source":"train_generator = generator(train_path, train_doc, batch_size)\nval_generator = generator(val_path, val_doc, batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:29:13.111307Z","iopub.execute_input":"2022-12-07T11:29:13.113542Z","iopub.status.idle":"2022-12-07T11:29:13.118744Z","shell.execute_reply.started":"2022-12-07T11:29:13.113512Z","shell.execute_reply":"2022-12-07T11:29:13.117746Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n    \nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n\nLR =  ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.0001)# write the REducelronplateau code here\ncallbacks_list = [checkpoint, LR]","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:29:13.212938Z","iopub.execute_input":"2022-12-07T11:29:13.213206Z","iopub.status.idle":"2022-12-07T11:29:13.220131Z","shell.execute_reply.started":"2022-12-07T11:29:13.213181Z","shell.execute_reply":"2022-12-07T11:29:13.219135Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make.","metadata":{}},{"cell_type":"code","source":"if (num_train_sequences%batch_size) == 0:\n    steps_per_epoch = int(num_train_sequences/batch_size)\nelse:\n    steps_per_epoch = (num_train_sequences//batch_size) + 1\n\nif (num_val_sequences%batch_size) == 0:\n    validation_steps = int(num_val_sequences/batch_size)\nelse:\n    validation_steps = (num_val_sequences//batch_size) + 1","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:29:13.342387Z","iopub.execute_input":"2022-12-07T11:29:13.343275Z","iopub.status.idle":"2022-12-07T11:29:13.349248Z","shell.execute_reply.started":"2022-12-07T11:29:13.343239Z","shell.execute_reply":"2022-12-07T11:29:13.348201Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch.","metadata":{}},{"cell_type":"code","source":"model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n                    callbacks=callbacks_list, validation_data=val_generator, \n                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T11:29:13.383324Z","iopub.execute_input":"2022-12-07T11:29:13.384202Z","iopub.status.idle":"2022-12-07T12:13:26.654959Z","shell.execute_reply.started":"2022-12-07T11:29:13.384167Z","shell.execute_reply":"2022-12-07T12:13:26.653831Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Source path =  /kaggle/input/gesture-recognition-upgrad/Project_data/train ; batch size = 20\nbatch 0\nEpoch 1/30\nbatch 1\n 1/34 [..............................] - ETA: 2:09 - loss: 4.0994 - categorical_accuracy: 0.2000batch 2\n 2/34 [>.............................] - ETA: 26s - loss: 6.7181 - categorical_accuracy: 0.2250 batch 3\n 3/34 [=>............................] - ETA: 1:04 - loss: 9.3253 - categorical_accuracy: 0.2500batch 4\n 4/34 [==>...........................] - ETA: 1:03 - loss: 11.4830 - categorical_accuracy: 0.2750batch 5\n 5/34 [===>..........................] - ETA: 1:01 - loss: 11.7624 - categorical_accuracy: 0.3100batch 6\n 6/34 [====>.........................] - ETA: 1:00 - loss: 12.2657 - categorical_accuracy: 0.3083batch 7\n 7/34 [=====>........................] - ETA: 1:01 - loss: 11.7060 - categorical_accuracy: 0.3071batch 8\n 8/34 [======>.......................] - ETA: 58s - loss: 10.7991 - categorical_accuracy: 0.2937 batch 9\n 9/34 [======>.......................] - ETA: 56s - loss: 10.3714 - categorical_accuracy: 0.2889batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 10.1311 - categorical_accuracy: 0.2750batch 11\n11/34 [========>.....................] - ETA: 52s - loss: 9.6409 - categorical_accuracy: 0.2682 batch 12\n12/34 [=========>....................] - ETA: 50s - loss: 9.2091 - categorical_accuracy: 0.2542batch 13\n13/34 [==========>...................] - ETA: 48s - loss: 8.7889 - categorical_accuracy: 0.2423batch 14\n14/34 [===========>..................] - ETA: 46s - loss: 8.3485 - categorical_accuracy: 0.2500batch 15\n15/34 [============>.................] - ETA: 44s - loss: 7.9266 - categorical_accuracy: 0.2567batch 16\n16/34 [=============>................] - ETA: 43s - loss: 7.6099 - categorical_accuracy: 0.2531batch 17\n17/34 [==============>...............] - ETA: 40s - loss: 7.3215 - categorical_accuracy: 0.2441batch 18\n18/34 [==============>...............] - ETA: 38s - loss: 7.0569 - categorical_accuracy: 0.2389batch 19\n19/34 [===============>..............] - ETA: 36s - loss: 6.8014 - categorical_accuracy: 0.2421batch 20\n20/34 [================>.............] - ETA: 33s - loss: 6.6188 - categorical_accuracy: 0.2375batch 21\n21/34 [=================>............] - ETA: 31s - loss: 6.4011 - categorical_accuracy: 0.2405batch 22\n22/34 [==================>...........] - ETA: 28s - loss: 6.2074 - categorical_accuracy: 0.2386batch 23\n23/34 [===================>..........] - ETA: 26s - loss: 6.0412 - categorical_accuracy: 0.2370batch 24\n24/34 [====================>.........] - ETA: 24s - loss: 5.8919 - categorical_accuracy: 0.2375batch 25\n25/34 [=====================>........] - ETA: 21s - loss: 5.7433 - categorical_accuracy: 0.2380batch 26\n26/34 [=====================>........] - ETA: 19s - loss: 5.6142 - categorical_accuracy: 0.2385batch 27\n27/34 [======================>.......] - ETA: 17s - loss: 5.4858 - categorical_accuracy: 0.2389batch 28\n28/34 [=======================>......] - ETA: 14s - loss: 5.3473 - categorical_accuracy: 0.2482batch 29\n29/34 [========================>.....] - ETA: 12s - loss: 5.2463 - categorical_accuracy: 0.2483batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 5.1554 - categorical_accuracy: 0.2433 batch 31\n31/34 [==========================>...] - ETA: 7s - loss: 5.0373 - categorical_accuracy: 0.2468batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 4.9603 - categorical_accuracy: 0.2438last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 4.8787 - categorical_accuracy: 0.2439batch 0\n34/34 [==============================] - ETA: 0s - loss: 4.8653 - categorical_accuracy: 0.2428Source path =  /kaggle/input/gesture-recognition-upgrad/Project_data/val ; batch size = 20\nbatch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 0\n34/34 [==============================] - 99s 3s/step - loss: 4.8653 - categorical_accuracy: 0.2428 - val_loss: 1.7906 - val_categorical_accuracy: 0.2000\n\nEpoch 00001: saving model to model_init_2022-12-0711_29_12.945522/model-00001-4.86527-0.24284-1.79061-0.20000.h5\nEpoch 2/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 2.5192 - categorical_accuracy: 0.2500batch 2\n 2/34 [>.............................] - ETA: 1:28 - loss: 2.4581 - categorical_accuracy: 0.2000batch 3\n 3/34 [=>............................] - ETA: 1:23 - loss: 2.2001 - categorical_accuracy: 0.2500batch 4\n 4/34 [==>...........................] - ETA: 1:16 - loss: 2.2516 - categorical_accuracy: 0.2250batch 5\n 5/34 [===>..........................] - ETA: 1:10 - loss: 2.1490 - categorical_accuracy: 0.2600batch 6\n 6/34 [====>.........................] - ETA: 1:07 - loss: 2.2024 - categorical_accuracy: 0.2750batch 7\n 7/34 [=====>........................] - ETA: 1:03 - loss: 2.1891 - categorical_accuracy: 0.2714batch 8\n 8/34 [======>.......................] - ETA: 1:01 - loss: 2.1132 - categorical_accuracy: 0.2812batch 9\n 9/34 [======>.......................] - ETA: 58s - loss: 2.0863 - categorical_accuracy: 0.2944 batch 10\n10/34 [=======>......................] - ETA: 55s - loss: 2.1013 - categorical_accuracy: 0.2900batch 11\n11/34 [========>.....................] - ETA: 53s - loss: 2.0849 - categorical_accuracy: 0.2818batch 12\n12/34 [=========>....................] - ETA: 50s - loss: 2.0362 - categorical_accuracy: 0.2917batch 13\n13/34 [==========>...................] - ETA: 48s - loss: 2.0383 - categorical_accuracy: 0.2808batch 14\n14/34 [===========>..................] - ETA: 46s - loss: 2.0602 - categorical_accuracy: 0.2821batch 15\n15/34 [============>.................] - ETA: 44s - loss: 2.0418 - categorical_accuracy: 0.2867batch 16\n16/34 [=============>................] - ETA: 41s - loss: 2.0102 - categorical_accuracy: 0.2969batch 17\n17/34 [==============>...............] - ETA: 39s - loss: 2.0007 - categorical_accuracy: 0.2912batch 18\n18/34 [==============>...............] - ETA: 37s - loss: 2.0065 - categorical_accuracy: 0.2944batch 19\n19/34 [===============>..............] - ETA: 34s - loss: 2.0020 - categorical_accuracy: 0.3000batch 20\n20/34 [================>.............] - ETA: 32s - loss: 2.0043 - categorical_accuracy: 0.3025batch 21\n21/34 [=================>............] - ETA: 29s - loss: 1.9873 - categorical_accuracy: 0.3024batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 1.9745 - categorical_accuracy: 0.3068batch 23\n23/34 [===================>..........] - ETA: 25s - loss: 1.9588 - categorical_accuracy: 0.3152batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 1.9503 - categorical_accuracy: 0.3167batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 1.9593 - categorical_accuracy: 0.3180batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 1.9637 - categorical_accuracy: 0.3135batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 1.9751 - categorical_accuracy: 0.3093batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 1.9633 - categorical_accuracy: 0.3125batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 1.9740 - categorical_accuracy: 0.3138batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 1.9540 - categorical_accuracy: 0.3217 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 1.9627 - categorical_accuracy: 0.3210batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 1.9425 - categorical_accuracy: 0.3266last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 1.9502 - categorical_accuracy: 0.3227batch 0\n34/34 [==============================] - ETA: 0s - loss: 1.9493 - categorical_accuracy: 0.3228batch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 0\nbatch 1\n34/34 [==============================] - 89s 3s/step - loss: 1.9493 - categorical_accuracy: 0.3228 - val_loss: 3.4859 - val_categorical_accuracy: 0.1500\n\nEpoch 00002: saving model to model_init_2022-12-0711_29_12.945522/model-00002-1.94931-0.32278-3.48588-0.15000.h5\nEpoch 3/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.9713 - categorical_accuracy: 0.3000batch 2\n 2/34 [>.............................] - ETA: 1:11 - loss: 2.1175 - categorical_accuracy: 0.2750batch 3\n 3/34 [=>............................] - ETA: 1:10 - loss: 1.8741 - categorical_accuracy: 0.3500batch 4\n 4/34 [==>...........................] - ETA: 1:10 - loss: 1.8876 - categorical_accuracy: 0.3625batch 5\n 5/34 [===>..........................] - ETA: 1:07 - loss: 1.9243 - categorical_accuracy: 0.3700batch 6\n 6/34 [====>.........................] - ETA: 1:03 - loss: 1.8623 - categorical_accuracy: 0.3833batch 7\n 7/34 [=====>........................] - ETA: 1:01 - loss: 1.8489 - categorical_accuracy: 0.3714batch 8\n 8/34 [======>.......................] - ETA: 58s - loss: 1.8819 - categorical_accuracy: 0.3625 batch 9\n 9/34 [======>.......................] - ETA: 56s - loss: 1.9029 - categorical_accuracy: 0.3500batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 1.8511 - categorical_accuracy: 0.3550batch 11\n11/34 [========>.....................] - ETA: 52s - loss: 1.8154 - categorical_accuracy: 0.3636batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 1.8310 - categorical_accuracy: 0.3583batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 1.8958 - categorical_accuracy: 0.3500batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 1.8842 - categorical_accuracy: 0.3536batch 15\n15/34 [============>.................] - ETA: 42s - loss: 1.8784 - categorical_accuracy: 0.3567batch 16\n16/34 [=============>................] - ETA: 40s - loss: 1.8755 - categorical_accuracy: 0.3562batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 1.8508 - categorical_accuracy: 0.3559batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 1.8596 - categorical_accuracy: 0.3583batch 19\n19/34 [===============>..............] - ETA: 34s - loss: 1.8737 - categorical_accuracy: 0.3526batch 20\n20/34 [================>.............] - ETA: 31s - loss: 1.8583 - categorical_accuracy: 0.3575batch 21\n21/34 [=================>............] - ETA: 29s - loss: 1.8569 - categorical_accuracy: 0.3548batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 1.8607 - categorical_accuracy: 0.3614batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 1.8595 - categorical_accuracy: 0.3587batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 1.8847 - categorical_accuracy: 0.3542batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 1.8774 - categorical_accuracy: 0.3520batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 1.8539 - categorical_accuracy: 0.3577batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 1.8432 - categorical_accuracy: 0.3593batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 1.8308 - categorical_accuracy: 0.3625batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 1.8216 - categorical_accuracy: 0.3621batch 30\n30/34 [=========================>....] - ETA: 8s - loss: 1.8065 - categorical_accuracy: 0.3617 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 1.7903 - categorical_accuracy: 0.3645batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 1.7948 - categorical_accuracy: 0.3625last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 1.7900 - categorical_accuracy: 0.3621batch 0\n34/34 [==============================] - ETA: 0s - loss: 1.7922 - categorical_accuracy: 0.3605batch 2\nbatch 3\nbatch 4\nbatch 0\nbatch 1\nbatch 2\n34/34 [==============================] - 88s 3s/step - loss: 1.7922 - categorical_accuracy: 0.3605 - val_loss: 4.6387 - val_categorical_accuracy: 0.2600\n\nEpoch 00003: saving model to model_init_2022-12-0711_29_12.945522/model-00003-1.79221-0.36048-4.63866-0.26000.h5\nEpoch 4/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 2.2124 - categorical_accuracy: 0.4000batch 2\n 2/34 [>.............................] - ETA: 1:05 - loss: 1.8067 - categorical_accuracy: 0.4250batch 3\n 3/34 [=>............................] - ETA: 1:06 - loss: 1.7461 - categorical_accuracy: 0.4000batch 4\n 4/34 [==>...........................] - ETA: 1:05 - loss: 1.9102 - categorical_accuracy: 0.3250batch 5\n 5/34 [===>..........................] - ETA: 1:03 - loss: 1.8343 - categorical_accuracy: 0.3100batch 6\n 6/34 [====>.........................] - ETA: 1:02 - loss: 1.8797 - categorical_accuracy: 0.3167batch 7\n 7/34 [=====>........................] - ETA: 1:02 - loss: 1.8232 - categorical_accuracy: 0.3571batch 8\n 8/34 [======>.......................] - ETA: 1:01 - loss: 1.7393 - categorical_accuracy: 0.3688batch 9\n 9/34 [======>.......................] - ETA: 57s - loss: 1.7434 - categorical_accuracy: 0.3611 batch 10\n10/34 [=======>......................] - ETA: 55s - loss: 1.6957 - categorical_accuracy: 0.3700batch 11\n11/34 [========>.....................] - ETA: 52s - loss: 1.6509 - categorical_accuracy: 0.3727batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 1.5987 - categorical_accuracy: 0.4000batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 1.5890 - categorical_accuracy: 0.4115batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 1.6321 - categorical_accuracy: 0.4107batch 15\n15/34 [============>.................] - ETA: 43s - loss: 1.6227 - categorical_accuracy: 0.4133batch 16\n16/34 [=============>................] - ETA: 40s - loss: 1.6468 - categorical_accuracy: 0.4031batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 1.6474 - categorical_accuracy: 0.4088batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 1.6566 - categorical_accuracy: 0.4083batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 1.6654 - categorical_accuracy: 0.4000batch 20\n20/34 [================>.............] - ETA: 31s - loss: 1.6501 - categorical_accuracy: 0.4050batch 21\n21/34 [=================>............] - ETA: 28s - loss: 1.6543 - categorical_accuracy: 0.4048batch 22\n22/34 [==================>...........] - ETA: 26s - loss: 1.6681 - categorical_accuracy: 0.4045batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 1.6562 - categorical_accuracy: 0.4043batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 1.6404 - categorical_accuracy: 0.4104batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 1.6242 - categorical_accuracy: 0.4120batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 1.6338 - categorical_accuracy: 0.4096batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 1.6364 - categorical_accuracy: 0.4074batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 1.6307 - categorical_accuracy: 0.4071batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 1.6385 - categorical_accuracy: 0.4086batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 1.6204 - categorical_accuracy: 0.4133 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 1.6003 - categorical_accuracy: 0.4194batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 1.6011 - categorical_accuracy: 0.4187last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 1.5971 - categorical_accuracy: 0.4227batch 0\n34/34 [==============================] - ETA: 0s - loss: 1.6057 - categorical_accuracy: 0.4208batch 3\nbatch 4\nbatch 0\nbatch 1\nbatch 2\nbatch 3\n34/34 [==============================] - 88s 3s/step - loss: 1.6057 - categorical_accuracy: 0.4208 - val_loss: 5.5247 - val_categorical_accuracy: 0.3200\n\nEpoch 00004: saving model to model_init_2022-12-0711_29_12.945522/model-00004-1.60567-0.42081-5.52471-0.32000.h5\nEpoch 5/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.0196 - categorical_accuracy: 0.5500batch 2\n 2/34 [>.............................] - ETA: 1:11 - loss: 1.5726 - categorical_accuracy: 0.4500batch 3\n 3/34 [=>............................] - ETA: 1:11 - loss: 1.7430 - categorical_accuracy: 0.4667batch 4\n 4/34 [==>...........................] - ETA: 1:09 - loss: 1.7549 - categorical_accuracy: 0.4500batch 5\n 5/34 [===>..........................] - ETA: 1:05 - loss: 1.6513 - categorical_accuracy: 0.4700batch 6\n 6/34 [====>.........................] - ETA: 1:02 - loss: 1.6644 - categorical_accuracy: 0.4500batch 7\n 7/34 [=====>........................] - ETA: 1:00 - loss: 1.5787 - categorical_accuracy: 0.4714batch 8\n 8/34 [======>.......................] - ETA: 58s - loss: 1.6102 - categorical_accuracy: 0.4563 batch 9\n 9/34 [======>.......................] - ETA: 55s - loss: 1.5728 - categorical_accuracy: 0.4611batch 10\n10/34 [=======>......................] - ETA: 53s - loss: 1.5921 - categorical_accuracy: 0.4500batch 11\n11/34 [========>.....................] - ETA: 52s - loss: 1.5975 - categorical_accuracy: 0.4364batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 1.5667 - categorical_accuracy: 0.4375batch 13\n13/34 [==========>...................] - ETA: 48s - loss: 1.5378 - categorical_accuracy: 0.4423batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 1.5447 - categorical_accuracy: 0.4357batch 15\n15/34 [============>.................] - ETA: 43s - loss: 1.5636 - categorical_accuracy: 0.4300batch 16\n16/34 [=============>................] - ETA: 40s - loss: 1.5901 - categorical_accuracy: 0.4219batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 1.5757 - categorical_accuracy: 0.4294batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 1.5963 - categorical_accuracy: 0.4222batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 1.5779 - categorical_accuracy: 0.4237batch 20\n20/34 [================>.............] - ETA: 31s - loss: 1.6011 - categorical_accuracy: 0.4175batch 21\n21/34 [=================>............] - ETA: 29s - loss: 1.5868 - categorical_accuracy: 0.4214batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 1.5739 - categorical_accuracy: 0.4227batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 1.5834 - categorical_accuracy: 0.4239batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 1.5901 - categorical_accuracy: 0.4187batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 1.5945 - categorical_accuracy: 0.4140batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 1.5828 - categorical_accuracy: 0.4154batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 1.5750 - categorical_accuracy: 0.4185batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 1.5717 - categorical_accuracy: 0.4196batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 1.5737 - categorical_accuracy: 0.4224batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 1.5837 - categorical_accuracy: 0.4233 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 1.5920 - categorical_accuracy: 0.4210batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 1.6040 - categorical_accuracy: 0.4219last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 1.6125 - categorical_accuracy: 0.4197batch 0\n34/34 [==============================] - ETA: 0s - loss: 1.6082 - categorical_accuracy: 0.4208batch 4\nbatch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\n34/34 [==============================] - 88s 3s/step - loss: 1.6082 - categorical_accuracy: 0.4208 - val_loss: 6.3188 - val_categorical_accuracy: 0.1900\n\nEpoch 00005: saving model to model_init_2022-12-0711_29_12.945522/model-00005-1.60824-0.42081-6.31876-0.19000.h5\nEpoch 6/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.4516 - categorical_accuracy: 0.5000batch 2\n 2/34 [>.............................] - ETA: 1:05 - loss: 1.5303 - categorical_accuracy: 0.4750batch 3\n 3/34 [=>............................] - ETA: 1:07 - loss: 1.6195 - categorical_accuracy: 0.4333batch 4\n 4/34 [==>...........................] - ETA: 1:04 - loss: 1.4655 - categorical_accuracy: 0.4875batch 5\n 5/34 [===>..........................] - ETA: 1:01 - loss: 1.5363 - categorical_accuracy: 0.4800batch 6\n 6/34 [====>.........................] - ETA: 58s - loss: 1.4886 - categorical_accuracy: 0.4917 batch 7\n 7/34 [=====>........................] - ETA: 57s - loss: 1.4671 - categorical_accuracy: 0.4714batch 8\n 8/34 [======>.......................] - ETA: 56s - loss: 1.4266 - categorical_accuracy: 0.4875batch 9\n 9/34 [======>.......................] - ETA: 54s - loss: 1.4230 - categorical_accuracy: 0.4833batch 10\n10/34 [=======>......................] - ETA: 52s - loss: 1.4509 - categorical_accuracy: 0.4800batch 11\n11/34 [========>.....................] - ETA: 49s - loss: 1.4435 - categorical_accuracy: 0.4818batch 12\n12/34 [=========>....................] - ETA: 47s - loss: 1.4770 - categorical_accuracy: 0.4833batch 13\n13/34 [==========>...................] - ETA: 46s - loss: 1.4604 - categorical_accuracy: 0.4885batch 14\n14/34 [===========>..................] - ETA: 44s - loss: 1.4571 - categorical_accuracy: 0.4893batch 15\n15/34 [============>.................] - ETA: 42s - loss: 1.4585 - categorical_accuracy: 0.4900batch 16\n16/34 [=============>................] - ETA: 40s - loss: 1.4477 - categorical_accuracy: 0.4969batch 17\n17/34 [==============>...............] - ETA: 37s - loss: 1.4547 - categorical_accuracy: 0.4941batch 18\n18/34 [==============>...............] - ETA: 35s - loss: 1.4269 - categorical_accuracy: 0.4972batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 1.4336 - categorical_accuracy: 0.4895batch 20\n20/34 [================>.............] - ETA: 31s - loss: 1.4199 - categorical_accuracy: 0.4900batch 21\n21/34 [=================>............] - ETA: 28s - loss: 1.4248 - categorical_accuracy: 0.4857batch 22\n22/34 [==================>...........] - ETA: 26s - loss: 1.4206 - categorical_accuracy: 0.4886batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 1.4275 - categorical_accuracy: 0.4826batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 1.4277 - categorical_accuracy: 0.4854batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 1.4205 - categorical_accuracy: 0.4960batch 26\n26/34 [=====================>........] - ETA: 17s - loss: 1.4135 - categorical_accuracy: 0.5019batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 1.4026 - categorical_accuracy: 0.5074batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 1.4155 - categorical_accuracy: 0.5054batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 1.4241 - categorical_accuracy: 0.5017batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 1.4609 - categorical_accuracy: 0.4917 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 1.4482 - categorical_accuracy: 0.4903batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 1.4361 - categorical_accuracy: 0.4922last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 1.4431 - categorical_accuracy: 0.4894batch 0\n34/34 [==============================] - ETA: 0s - loss: 1.4414 - categorical_accuracy: 0.4887batch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 0\n34/34 [==============================] - 87s 3s/step - loss: 1.4414 - categorical_accuracy: 0.4887 - val_loss: 6.3435 - val_categorical_accuracy: 0.1900\n\nEpoch 00006: saving model to model_init_2022-12-0711_29_12.945522/model-00006-1.44141-0.48869-6.34348-0.19000.h5\n\nEpoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\nEpoch 7/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.5087 - categorical_accuracy: 0.5000batch 2\n 2/34 [>.............................] - ETA: 1:24 - loss: 1.7242 - categorical_accuracy: 0.4750batch 3\n 3/34 [=>............................] - ETA: 1:21 - loss: 1.7385 - categorical_accuracy: 0.4333batch 4\n 4/34 [==>...........................] - ETA: 1:14 - loss: 1.6650 - categorical_accuracy: 0.4625batch 5\n 5/34 [===>..........................] - ETA: 1:09 - loss: 1.7840 - categorical_accuracy: 0.4500batch 6\n 6/34 [====>.........................] - ETA: 1:05 - loss: 1.7131 - categorical_accuracy: 0.4500batch 7\n 7/34 [=====>........................] - ETA: 1:02 - loss: 1.6279 - categorical_accuracy: 0.4786batch 8\n 8/34 [======>.......................] - ETA: 1:00 - loss: 1.5536 - categorical_accuracy: 0.4750batch 9\n 9/34 [======>.......................] - ETA: 57s - loss: 1.6147 - categorical_accuracy: 0.4667 batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 1.5414 - categorical_accuracy: 0.4850batch 11\n11/34 [========>.....................] - ETA: 52s - loss: 1.5120 - categorical_accuracy: 0.4955batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 1.4934 - categorical_accuracy: 0.4958batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 1.4643 - categorical_accuracy: 0.5000batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 1.4618 - categorical_accuracy: 0.5036batch 15\n15/34 [============>.................] - ETA: 43s - loss: 1.4701 - categorical_accuracy: 0.4967batch 16\n16/34 [=============>................] - ETA: 41s - loss: 1.4388 - categorical_accuracy: 0.5094batch 17\n17/34 [==============>...............] - ETA: 39s - loss: 1.4743 - categorical_accuracy: 0.4941batch 18\n18/34 [==============>...............] - ETA: 37s - loss: 1.4455 - categorical_accuracy: 0.5028batch 19\n19/34 [===============>..............] - ETA: 34s - loss: 1.4513 - categorical_accuracy: 0.5000batch 20\n20/34 [================>.............] - ETA: 32s - loss: 1.4306 - categorical_accuracy: 0.5025batch 21\n21/34 [=================>............] - ETA: 29s - loss: 1.4319 - categorical_accuracy: 0.5024batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 1.4164 - categorical_accuracy: 0.5068batch 23\n23/34 [===================>..........] - ETA: 25s - loss: 1.4256 - categorical_accuracy: 0.5043batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 1.4182 - categorical_accuracy: 0.5042batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 1.4063 - categorical_accuracy: 0.5080batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 1.3905 - categorical_accuracy: 0.5115batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 1.3604 - categorical_accuracy: 0.5222batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 1.3573 - categorical_accuracy: 0.5214batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 1.3622 - categorical_accuracy: 0.5172batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 1.3598 - categorical_accuracy: 0.5150 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 1.3557 - categorical_accuracy: 0.5145batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 1.3591 - categorical_accuracy: 0.5125last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 1.3452 - categorical_accuracy: 0.5167batch 0\n34/34 [==============================] - ETA: 0s - loss: 1.3412 - categorical_accuracy: 0.5189batch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 0\nbatch 1\n34/34 [==============================] - 88s 3s/step - loss: 1.3412 - categorical_accuracy: 0.5189 - val_loss: 6.6001 - val_categorical_accuracy: 0.2500\n\nEpoch 00007: saving model to model_init_2022-12-0711_29_12.945522/model-00007-1.34119-0.51885-6.60012-0.25000.h5\nEpoch 8/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.3674 - categorical_accuracy: 0.5500batch 2\n 2/34 [>.............................] - ETA: 1:27 - loss: 1.2449 - categorical_accuracy: 0.6250batch 3\n 3/34 [=>............................] - ETA: 1:21 - loss: 1.1257 - categorical_accuracy: 0.6167batch 4\n 4/34 [==>...........................] - ETA: 1:13 - loss: 1.0388 - categorical_accuracy: 0.6375batch 5\n 5/34 [===>..........................] - ETA: 1:11 - loss: 1.0012 - categorical_accuracy: 0.6200batch 6\n 6/34 [====>.........................] - ETA: 1:07 - loss: 1.0921 - categorical_accuracy: 0.6000batch 7\n 7/34 [=====>........................] - ETA: 1:04 - loss: 1.1289 - categorical_accuracy: 0.5929batch 8\n 8/34 [======>.......................] - ETA: 1:01 - loss: 1.1279 - categorical_accuracy: 0.5938batch 9\n 9/34 [======>.......................] - ETA: 59s - loss: 1.0858 - categorical_accuracy: 0.6056 batch 10\n10/34 [=======>......................] - ETA: 56s - loss: 1.0644 - categorical_accuracy: 0.6050batch 11\n11/34 [========>.....................] - ETA: 53s - loss: 1.0883 - categorical_accuracy: 0.6000batch 12\n12/34 [=========>....................] - ETA: 51s - loss: 1.1038 - categorical_accuracy: 0.6000batch 13\n13/34 [==========>...................] - ETA: 48s - loss: 1.1206 - categorical_accuracy: 0.5962batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 1.1146 - categorical_accuracy: 0.5964batch 15\n15/34 [============>.................] - ETA: 43s - loss: 1.1109 - categorical_accuracy: 0.6033batch 16\n16/34 [=============>................] - ETA: 41s - loss: 1.1157 - categorical_accuracy: 0.6000batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 1.1202 - categorical_accuracy: 0.5971batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 1.1328 - categorical_accuracy: 0.5917batch 19\n19/34 [===============>..............] - ETA: 34s - loss: 1.1584 - categorical_accuracy: 0.5842batch 20\n20/34 [================>.............] - ETA: 32s - loss: 1.1631 - categorical_accuracy: 0.5800batch 21\n21/34 [=================>............] - ETA: 29s - loss: 1.1606 - categorical_accuracy: 0.5762batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 1.1610 - categorical_accuracy: 0.5795batch 23\n23/34 [===================>..........] - ETA: 25s - loss: 1.1384 - categorical_accuracy: 0.5848batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 1.1353 - categorical_accuracy: 0.5833batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 1.1530 - categorical_accuracy: 0.5760batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 1.1688 - categorical_accuracy: 0.5788batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 1.1679 - categorical_accuracy: 0.5759batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 1.1848 - categorical_accuracy: 0.5732batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 1.1748 - categorical_accuracy: 0.5724batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 1.1708 - categorical_accuracy: 0.5733 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 1.1707 - categorical_accuracy: 0.5710batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 1.1695 - categorical_accuracy: 0.5703last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 1.1610 - categorical_accuracy: 0.5712batch 0\n34/34 [==============================] - ETA: 0s - loss: 1.1573 - categorical_accuracy: 0.5732batch 2\nbatch 3\nbatch 4\nbatch 0\nbatch 1\nbatch 2\n34/34 [==============================] - 89s 3s/step - loss: 1.1573 - categorical_accuracy: 0.5732 - val_loss: 6.6935 - val_categorical_accuracy: 0.2700\n\nEpoch 00008: saving model to model_init_2022-12-0711_29_12.945522/model-00008-1.15732-0.57315-6.69353-0.27000.h5\nEpoch 9/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.2874 - categorical_accuracy: 0.4500batch 2\n 2/34 [>.............................] - ETA: 1:20 - loss: 1.1774 - categorical_accuracy: 0.5500batch 3\n 3/34 [=>............................] - ETA: 1:13 - loss: 1.1714 - categorical_accuracy: 0.5500batch 4\n 4/34 [==>...........................] - ETA: 1:09 - loss: 1.0756 - categorical_accuracy: 0.5875batch 5\n 5/34 [===>..........................] - ETA: 1:05 - loss: 1.0419 - categorical_accuracy: 0.6200batch 6\n 6/34 [====>.........................] - ETA: 1:03 - loss: 1.0342 - categorical_accuracy: 0.6333batch 7\n 7/34 [=====>........................] - ETA: 1:01 - loss: 1.0002 - categorical_accuracy: 0.6500batch 8\n 8/34 [======>.......................] - ETA: 1:00 - loss: 1.0087 - categorical_accuracy: 0.6438batch 9\n 9/34 [======>.......................] - ETA: 57s - loss: 1.0429 - categorical_accuracy: 0.6444 batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 1.0883 - categorical_accuracy: 0.6300batch 11\n11/34 [========>.....................] - ETA: 52s - loss: 1.1204 - categorical_accuracy: 0.6091batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 1.1207 - categorical_accuracy: 0.6000batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 1.0893 - categorical_accuracy: 0.6154batch 14\n14/34 [===========>..................] - ETA: 44s - loss: 1.0804 - categorical_accuracy: 0.6107batch 15\n15/34 [============>.................] - ETA: 42s - loss: 1.1238 - categorical_accuracy: 0.6033batch 16\n16/34 [=============>................] - ETA: 40s - loss: 1.1089 - categorical_accuracy: 0.6031batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 1.1014 - categorical_accuracy: 0.6029batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 1.1376 - categorical_accuracy: 0.5889batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 1.1179 - categorical_accuracy: 0.5947batch 20\n20/34 [================>.............] - ETA: 31s - loss: 1.0886 - categorical_accuracy: 0.6050batch 21\n21/34 [=================>............] - ETA: 29s - loss: 1.1019 - categorical_accuracy: 0.6000batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 1.1130 - categorical_accuracy: 0.6045batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 1.1005 - categorical_accuracy: 0.6043batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 1.1299 - categorical_accuracy: 0.5938batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 1.1201 - categorical_accuracy: 0.5960batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 1.1181 - categorical_accuracy: 0.5942batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 1.1380 - categorical_accuracy: 0.5889batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 1.1359 - categorical_accuracy: 0.5875batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 1.1290 - categorical_accuracy: 0.5862batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 1.1255 - categorical_accuracy: 0.5850 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 1.1140 - categorical_accuracy: 0.5871batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 1.1141 - categorical_accuracy: 0.5875last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 1.1404 - categorical_accuracy: 0.5833batch 0\n34/34 [==============================] - ETA: 0s - loss: 1.1500 - categorical_accuracy: 0.5822batch 3\nbatch 4\nbatch 0\nbatch 1\nbatch 2\nbatch 3\n34/34 [==============================] - 88s 3s/step - loss: 1.1500 - categorical_accuracy: 0.5822 - val_loss: 5.0309 - val_categorical_accuracy: 0.3600\n\nEpoch 00009: saving model to model_init_2022-12-0711_29_12.945522/model-00009-1.14998-0.58220-5.03095-0.36000.h5\nEpoch 10/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.7057 - categorical_accuracy: 0.5000batch 2\n 2/34 [>.............................] - ETA: 1:22 - loss: 1.6037 - categorical_accuracy: 0.4750batch 3\n 3/34 [=>............................] - ETA: 1:19 - loss: 1.4549 - categorical_accuracy: 0.4833batch 4\n 4/34 [==>...........................] - ETA: 1:13 - loss: 1.4619 - categorical_accuracy: 0.4625batch 5\n 5/34 [===>..........................] - ETA: 1:10 - loss: 1.3261 - categorical_accuracy: 0.4900batch 6\n 6/34 [====>.........................] - ETA: 1:06 - loss: 1.2342 - categorical_accuracy: 0.5250batch 7\n 7/34 [=====>........................] - ETA: 1:03 - loss: 1.1784 - categorical_accuracy: 0.5286batch 8\n 8/34 [======>.......................] - ETA: 1:01 - loss: 1.1266 - categorical_accuracy: 0.5375batch 9\n 9/34 [======>.......................] - ETA: 58s - loss: 1.1140 - categorical_accuracy: 0.5333 batch 10\n10/34 [=======>......................] - ETA: 55s - loss: 1.1070 - categorical_accuracy: 0.5300batch 11\n11/34 [========>.....................] - ETA: 53s - loss: 1.0999 - categorical_accuracy: 0.5364batch 12\n12/34 [=========>....................] - ETA: 51s - loss: 1.0797 - categorical_accuracy: 0.5458batch 13\n13/34 [==========>...................] - ETA: 48s - loss: 1.1128 - categorical_accuracy: 0.5385batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 1.1034 - categorical_accuracy: 0.5250batch 15\n15/34 [============>.................] - ETA: 43s - loss: 1.0950 - categorical_accuracy: 0.5267batch 16\n16/34 [=============>................] - ETA: 41s - loss: 1.1003 - categorical_accuracy: 0.5312batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 1.0729 - categorical_accuracy: 0.5441batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 1.1215 - categorical_accuracy: 0.5333batch 19\n19/34 [===============>..............] - ETA: 34s - loss: 1.1511 - categorical_accuracy: 0.5316batch 20\n20/34 [================>.............] - ETA: 31s - loss: 1.1824 - categorical_accuracy: 0.5225batch 21\n21/34 [=================>............] - ETA: 29s - loss: 1.2044 - categorical_accuracy: 0.5167batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 1.2115 - categorical_accuracy: 0.5205batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 1.1885 - categorical_accuracy: 0.5304batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 1.1690 - categorical_accuracy: 0.5417batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 1.1537 - categorical_accuracy: 0.5480batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 1.1331 - categorical_accuracy: 0.5538batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 1.1122 - categorical_accuracy: 0.5630batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 1.1156 - categorical_accuracy: 0.5661batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 1.1095 - categorical_accuracy: 0.5707batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 1.1066 - categorical_accuracy: 0.5750 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 1.1043 - categorical_accuracy: 0.5710batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 1.1086 - categorical_accuracy: 0.5766last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 1.1067 - categorical_accuracy: 0.5758batch 0\n34/34 [==============================] - ETA: 0s - loss: 1.1059 - categorical_accuracy: 0.5762batch 4\nbatch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\n34/34 [==============================] - 89s 3s/step - loss: 1.1059 - categorical_accuracy: 0.5762 - val_loss: 5.8421 - val_categorical_accuracy: 0.2700\n\nEpoch 00010: saving model to model_init_2022-12-0711_29_12.945522/model-00010-1.10588-0.57617-5.84211-0.27000.h5\nEpoch 11/30\nbatch 1\n 1/34 [..............................] - ETA: 27s - loss: 0.9319 - categorical_accuracy: 0.6500batch 2\n 2/34 [>.............................] - ETA: 1:18 - loss: 0.9289 - categorical_accuracy: 0.7000batch 3\n 3/34 [=>............................] - ETA: 1:08 - loss: 0.9628 - categorical_accuracy: 0.6833batch 4\n 4/34 [==>...........................] - ETA: 1:06 - loss: 1.0369 - categorical_accuracy: 0.6625batch 5\n 5/34 [===>..........................] - ETA: 1:03 - loss: 1.0351 - categorical_accuracy: 0.7000batch 6\n 6/34 [====>.........................] - ETA: 1:01 - loss: 1.0444 - categorical_accuracy: 0.6750batch 7\n 7/34 [=====>........................] - ETA: 1:00 - loss: 1.0451 - categorical_accuracy: 0.6571batch 8\n 8/34 [======>.......................] - ETA: 57s - loss: 0.9986 - categorical_accuracy: 0.6687 batch 9\n 9/34 [======>.......................] - ETA: 54s - loss: 1.0164 - categorical_accuracy: 0.6500batch 10\n10/34 [=======>......................] - ETA: 51s - loss: 1.0235 - categorical_accuracy: 0.6400batch 11\n11/34 [========>.....................] - ETA: 49s - loss: 1.0327 - categorical_accuracy: 0.6318batch 12\n12/34 [=========>....................] - ETA: 47s - loss: 1.0761 - categorical_accuracy: 0.6167batch 13\n13/34 [==========>...................] - ETA: 45s - loss: 1.0472 - categorical_accuracy: 0.6192batch 14\n14/34 [===========>..................] - ETA: 44s - loss: 1.0175 - categorical_accuracy: 0.6286batch 15\n15/34 [============>.................] - ETA: 42s - loss: 1.0102 - categorical_accuracy: 0.6333batch 16\n16/34 [=============>................] - ETA: 40s - loss: 1.0286 - categorical_accuracy: 0.6250batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 1.0564 - categorical_accuracy: 0.6118batch 18\n18/34 [==============>...............] - ETA: 35s - loss: 1.0708 - categorical_accuracy: 0.6056batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 1.0572 - categorical_accuracy: 0.6105batch 20\n20/34 [================>.............] - ETA: 31s - loss: 1.0735 - categorical_accuracy: 0.6050batch 21\n21/34 [=================>............] - ETA: 28s - loss: 1.1040 - categorical_accuracy: 0.5976batch 22\n22/34 [==================>...........] - ETA: 26s - loss: 1.0859 - categorical_accuracy: 0.6023batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 1.0872 - categorical_accuracy: 0.6000batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 1.1282 - categorical_accuracy: 0.5875batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 1.1305 - categorical_accuracy: 0.5880batch 26\n26/34 [=====================>........] - ETA: 17s - loss: 1.1268 - categorical_accuracy: 0.5865batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 1.1140 - categorical_accuracy: 0.5870batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 1.1084 - categorical_accuracy: 0.5893batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 1.1085 - categorical_accuracy: 0.5897batch 30\n30/34 [=========================>....] - ETA: 8s - loss: 1.1122 - categorical_accuracy: 0.5850 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 1.1100 - categorical_accuracy: 0.5823batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 1.1131 - categorical_accuracy: 0.5875last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 1.1105 - categorical_accuracy: 0.5879batch 0\n34/34 [==============================] - ETA: 0s - loss: 1.1081 - categorical_accuracy: 0.5882batch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 0\n34/34 [==============================] - 87s 3s/step - loss: 1.1081 - categorical_accuracy: 0.5882 - val_loss: 4.3093 - val_categorical_accuracy: 0.3000\n\nEpoch 00011: saving model to model_init_2022-12-0711_29_12.945522/model-00011-1.10807-0.58824-4.30929-0.30000.h5\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001.\nEpoch 12/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 0.6831 - categorical_accuracy: 0.7000batch 2\n 2/34 [>.............................] - ETA: 1:19 - loss: 0.8407 - categorical_accuracy: 0.6500batch 3\n 3/34 [=>............................] - ETA: 1:16 - loss: 0.9009 - categorical_accuracy: 0.6333batch 4\n 4/34 [==>...........................] - ETA: 1:11 - loss: 0.8575 - categorical_accuracy: 0.6625batch 5\n 5/34 [===>..........................] - ETA: 1:07 - loss: 0.9170 - categorical_accuracy: 0.6200batch 6\n 6/34 [====>.........................] - ETA: 1:04 - loss: 0.9234 - categorical_accuracy: 0.6250batch 7\n 7/34 [=====>........................] - ETA: 1:01 - loss: 0.9580 - categorical_accuracy: 0.6071batch 8\n 8/34 [======>.......................] - ETA: 59s - loss: 0.9981 - categorical_accuracy: 0.6062 batch 9\n 9/34 [======>.......................] - ETA: 56s - loss: 1.0174 - categorical_accuracy: 0.5944batch 10\n10/34 [=======>......................] - ETA: 53s - loss: 0.9999 - categorical_accuracy: 0.6050batch 11\n11/34 [========>.....................] - ETA: 51s - loss: 0.9937 - categorical_accuracy: 0.6091batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 1.0137 - categorical_accuracy: 0.6000batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 0.9676 - categorical_accuracy: 0.6154batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 0.9777 - categorical_accuracy: 0.6143batch 15\n15/34 [============>.................] - ETA: 42s - loss: 0.9798 - categorical_accuracy: 0.6167batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.9675 - categorical_accuracy: 0.6156batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 0.9842 - categorical_accuracy: 0.6118batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 0.9933 - categorical_accuracy: 0.6111batch 19\n19/34 [===============>..............] - ETA: 34s - loss: 1.0158 - categorical_accuracy: 0.6079batch 20\n20/34 [================>.............] - ETA: 31s - loss: 1.0105 - categorical_accuracy: 0.6075batch 21\n21/34 [=================>............] - ETA: 29s - loss: 1.0111 - categorical_accuracy: 0.6048batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 1.0227 - categorical_accuracy: 0.6045batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 1.0148 - categorical_accuracy: 0.6043batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 1.0287 - categorical_accuracy: 0.6000batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 1.0146 - categorical_accuracy: 0.6020batch 26\n26/34 [=====================>........] - ETA: 17s - loss: 1.0321 - categorical_accuracy: 0.5962batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 1.0214 - categorical_accuracy: 0.5981batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 1.0126 - categorical_accuracy: 0.6018batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 1.0369 - categorical_accuracy: 0.5966batch 30\n30/34 [=========================>....] - ETA: 8s - loss: 1.0226 - categorical_accuracy: 0.6017 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 1.0246 - categorical_accuracy: 0.6032batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 1.0404 - categorical_accuracy: 0.6000last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 1.0379 - categorical_accuracy: 0.6015batch 0\n34/34 [==============================] - ETA: 0s - loss: 1.0389 - categorical_accuracy: 0.6018batch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 0\nbatch 1\n34/34 [==============================] - 88s 3s/step - loss: 1.0389 - categorical_accuracy: 0.6018 - val_loss: 3.6850 - val_categorical_accuracy: 0.3400\n\nEpoch 00012: saving model to model_init_2022-12-0711_29_12.945522/model-00012-1.03892-0.60181-3.68500-0.34000.h5\nEpoch 13/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 0.7546 - categorical_accuracy: 0.7000batch 2\n 2/34 [>.............................] - ETA: 1:17 - loss: 0.7708 - categorical_accuracy: 0.7750batch 3\n 3/34 [=>............................] - ETA: 1:10 - loss: 0.8385 - categorical_accuracy: 0.7167batch 4\n 4/34 [==>...........................] - ETA: 1:07 - loss: 0.9158 - categorical_accuracy: 0.6750batch 5\n 5/34 [===>..........................] - ETA: 1:04 - loss: 0.9189 - categorical_accuracy: 0.6700batch 6\n 6/34 [====>.........................] - ETA: 1:03 - loss: 0.8676 - categorical_accuracy: 0.6917batch 7\n 7/34 [=====>........................] - ETA: 1:01 - loss: 0.8696 - categorical_accuracy: 0.6929batch 8\n 8/34 [======>.......................] - ETA: 59s - loss: 0.9167 - categorical_accuracy: 0.6625 batch 9\n 9/34 [======>.......................] - ETA: 56s - loss: 1.0266 - categorical_accuracy: 0.6444batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 1.0134 - categorical_accuracy: 0.6400batch 11\n11/34 [========>.....................] - ETA: 51s - loss: 1.0043 - categorical_accuracy: 0.6409batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 1.0133 - categorical_accuracy: 0.6375batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 1.0310 - categorical_accuracy: 0.6308batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 1.0157 - categorical_accuracy: 0.6357batch 15\n15/34 [============>.................] - ETA: 42s - loss: 0.9793 - categorical_accuracy: 0.6500batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.9881 - categorical_accuracy: 0.6438batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 0.9825 - categorical_accuracy: 0.6382batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 0.9823 - categorical_accuracy: 0.6306batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 0.9735 - categorical_accuracy: 0.6289batch 20\n20/34 [================>.............] - ETA: 31s - loss: 0.9525 - categorical_accuracy: 0.6375batch 21\n21/34 [=================>............] - ETA: 29s - loss: 0.9374 - categorical_accuracy: 0.6452batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 0.9308 - categorical_accuracy: 0.6455batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.9453 - categorical_accuracy: 0.6348batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.9427 - categorical_accuracy: 0.6354batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.9518 - categorical_accuracy: 0.6320batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 0.9511 - categorical_accuracy: 0.6385batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.9473 - categorical_accuracy: 0.6389batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.9429 - categorical_accuracy: 0.6393batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.9623 - categorical_accuracy: 0.6345batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 0.9644 - categorical_accuracy: 0.6333 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.9635 - categorical_accuracy: 0.6355batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.9677 - categorical_accuracy: 0.6359last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.9555 - categorical_accuracy: 0.6424batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.9552 - categorical_accuracy: 0.6425batch 2\nbatch 3\nbatch 4\nbatch 0\nbatch 1\nbatch 2\n34/34 [==============================] - 87s 3s/step - loss: 0.9552 - categorical_accuracy: 0.6425 - val_loss: 3.0275 - val_categorical_accuracy: 0.3300\n\nEpoch 00013: saving model to model_init_2022-12-0711_29_12.945522/model-00013-0.95516-0.64253-3.02748-0.33000.h5\nEpoch 14/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.0086 - categorical_accuracy: 0.6000batch 2\n 2/34 [>.............................] - ETA: 1:16 - loss: 0.8925 - categorical_accuracy: 0.6750batch 3\n 3/34 [=>............................] - ETA: 1:13 - loss: 0.9002 - categorical_accuracy: 0.6667batch 4\n 4/34 [==>...........................] - ETA: 1:09 - loss: 0.9558 - categorical_accuracy: 0.6500batch 5\n 5/34 [===>..........................] - ETA: 1:05 - loss: 1.0590 - categorical_accuracy: 0.6000batch 6\n 6/34 [====>.........................] - ETA: 1:02 - loss: 1.0926 - categorical_accuracy: 0.6083batch 7\n 7/34 [=====>........................] - ETA: 1:01 - loss: 1.1673 - categorical_accuracy: 0.5857batch 8\n 8/34 [======>.......................] - ETA: 58s - loss: 1.0889 - categorical_accuracy: 0.6187 batch 9\n 9/34 [======>.......................] - ETA: 57s - loss: 1.1222 - categorical_accuracy: 0.6222batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 1.1073 - categorical_accuracy: 0.6250batch 11\n11/34 [========>.....................] - ETA: 51s - loss: 1.0627 - categorical_accuracy: 0.6318batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 1.0548 - categorical_accuracy: 0.6333batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 1.0866 - categorical_accuracy: 0.6346batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 1.0770 - categorical_accuracy: 0.6321batch 15\n15/34 [============>.................] - ETA: 42s - loss: 1.0651 - categorical_accuracy: 0.6333batch 16\n16/34 [=============>................] - ETA: 40s - loss: 1.0620 - categorical_accuracy: 0.6313batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 1.0613 - categorical_accuracy: 0.6294batch 18\n18/34 [==============>...............] - ETA: 35s - loss: 1.0513 - categorical_accuracy: 0.6306batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 1.0248 - categorical_accuracy: 0.6368batch 20\n20/34 [================>.............] - ETA: 31s - loss: 1.0255 - categorical_accuracy: 0.6350batch 21\n21/34 [=================>............] - ETA: 29s - loss: 1.0111 - categorical_accuracy: 0.6381batch 22\n22/34 [==================>...........] - ETA: 26s - loss: 0.9974 - categorical_accuracy: 0.6477batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.9705 - categorical_accuracy: 0.6565batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.9559 - categorical_accuracy: 0.6583batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.9505 - categorical_accuracy: 0.6620batch 26\n26/34 [=====================>........] - ETA: 17s - loss: 0.9537 - categorical_accuracy: 0.6596batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.9623 - categorical_accuracy: 0.6556batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.9614 - categorical_accuracy: 0.6571batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.9555 - categorical_accuracy: 0.6603batch 30\n30/34 [=========================>....] - ETA: 8s - loss: 0.9417 - categorical_accuracy: 0.6667 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.9550 - categorical_accuracy: 0.6645batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.9627 - categorical_accuracy: 0.6609last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.9593 - categorical_accuracy: 0.6591batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.9583 - categorical_accuracy: 0.6576batch 3\nbatch 4\nbatch 0\nbatch 1\nbatch 2\nbatch 3\n34/34 [==============================] - 87s 3s/step - loss: 0.9583 - categorical_accuracy: 0.6576 - val_loss: 2.3089 - val_categorical_accuracy: 0.4400\n\nEpoch 00014: saving model to model_init_2022-12-0711_29_12.945522/model-00014-0.95832-0.65762-2.30887-0.44000.h5\nEpoch 15/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 0.5591 - categorical_accuracy: 0.8000batch 2\n 2/34 [>.............................] - ETA: 1:12 - loss: 0.8476 - categorical_accuracy: 0.6250batch 3\n 3/34 [=>............................] - ETA: 1:11 - loss: 0.7474 - categorical_accuracy: 0.7000batch 4\n 4/34 [==>...........................] - ETA: 1:07 - loss: 0.9539 - categorical_accuracy: 0.6875batch 5\n 5/34 [===>..........................] - ETA: 1:04 - loss: 0.9283 - categorical_accuracy: 0.6800batch 6\n 6/34 [====>.........................] - ETA: 1:00 - loss: 0.8949 - categorical_accuracy: 0.6833batch 7\n 7/34 [=====>........................] - ETA: 58s - loss: 0.8770 - categorical_accuracy: 0.6857 batch 8\n 8/34 [======>.......................] - ETA: 57s - loss: 0.8561 - categorical_accuracy: 0.6812batch 9\n 9/34 [======>.......................] - ETA: 55s - loss: 0.8667 - categorical_accuracy: 0.6778batch 10\n10/34 [=======>......................] - ETA: 52s - loss: 0.8676 - categorical_accuracy: 0.6800batch 11\n11/34 [========>.....................] - ETA: 50s - loss: 0.8406 - categorical_accuracy: 0.6864batch 12\n12/34 [=========>....................] - ETA: 48s - loss: 0.8457 - categorical_accuracy: 0.6917batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 0.8649 - categorical_accuracy: 0.6808batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 0.8788 - categorical_accuracy: 0.6714batch 15\n15/34 [============>.................] - ETA: 42s - loss: 0.8809 - categorical_accuracy: 0.6767batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.8548 - categorical_accuracy: 0.6875batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 0.8580 - categorical_accuracy: 0.6882batch 18\n18/34 [==============>...............] - ETA: 35s - loss: 0.8627 - categorical_accuracy: 0.6833batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 0.8696 - categorical_accuracy: 0.6868batch 20\n20/34 [================>.............] - ETA: 31s - loss: 0.8770 - categorical_accuracy: 0.6800batch 21\n21/34 [=================>............] - ETA: 29s - loss: 0.8607 - categorical_accuracy: 0.6857batch 22\n22/34 [==================>...........] - ETA: 26s - loss: 0.8565 - categorical_accuracy: 0.6886batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.8798 - categorical_accuracy: 0.6804batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.9077 - categorical_accuracy: 0.6729batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.9323 - categorical_accuracy: 0.6640batch 26\n26/34 [=====================>........] - ETA: 17s - loss: 0.9312 - categorical_accuracy: 0.6615batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.9272 - categorical_accuracy: 0.6630batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.9163 - categorical_accuracy: 0.6643batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.9093 - categorical_accuracy: 0.6655batch 30\n30/34 [=========================>....] - ETA: 8s - loss: 0.9076 - categorical_accuracy: 0.6650 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.8978 - categorical_accuracy: 0.6694batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.8912 - categorical_accuracy: 0.6687last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.8895 - categorical_accuracy: 0.6697batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.8869 - categorical_accuracy: 0.6712batch 4\nbatch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\n34/34 [==============================] - 87s 3s/step - loss: 0.8869 - categorical_accuracy: 0.6712 - val_loss: 2.0018 - val_categorical_accuracy: 0.4700\n\nEpoch 00015: saving model to model_init_2022-12-0711_29_12.945522/model-00015-0.88690-0.67119-2.00179-0.47000.h5\nEpoch 16/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 0.8217 - categorical_accuracy: 0.6500batch 2\n 2/34 [>.............................] - ETA: 1:30 - loss: 0.9658 - categorical_accuracy: 0.6000batch 3\n 3/34 [=>............................] - ETA: 1:23 - loss: 1.0761 - categorical_accuracy: 0.5833batch 4\n 4/34 [==>...........................] - ETA: 1:15 - loss: 1.1489 - categorical_accuracy: 0.6000batch 5\n 5/34 [===>..........................] - ETA: 1:11 - loss: 1.1328 - categorical_accuracy: 0.6100batch 6\n 6/34 [====>.........................] - ETA: 1:07 - loss: 1.0704 - categorical_accuracy: 0.6167batch 7\n 7/34 [=====>........................] - ETA: 1:04 - loss: 1.1065 - categorical_accuracy: 0.6143batch 8\n 8/34 [======>.......................] - ETA: 1:02 - loss: 1.1074 - categorical_accuracy: 0.6125batch 9\n 9/34 [======>.......................] - ETA: 59s - loss: 1.0679 - categorical_accuracy: 0.6278 batch 10\n10/34 [=======>......................] - ETA: 56s - loss: 1.0908 - categorical_accuracy: 0.6100batch 11\n11/34 [========>.....................] - ETA: 54s - loss: 1.1055 - categorical_accuracy: 0.6000batch 12\n12/34 [=========>....................] - ETA: 52s - loss: 1.0726 - categorical_accuracy: 0.6042batch 13\n13/34 [==========>...................] - ETA: 49s - loss: 1.0595 - categorical_accuracy: 0.6038batch 14\n14/34 [===========>..................] - ETA: 46s - loss: 1.0423 - categorical_accuracy: 0.6107batch 15\n15/34 [============>.................] - ETA: 43s - loss: 1.0166 - categorical_accuracy: 0.6267batch 16\n16/34 [=============>................] - ETA: 42s - loss: 0.9838 - categorical_accuracy: 0.6406batch 17\n17/34 [==============>...............] - ETA: 40s - loss: 0.9983 - categorical_accuracy: 0.6353batch 18\n18/34 [==============>...............] - ETA: 37s - loss: 0.9920 - categorical_accuracy: 0.6389batch 19\n19/34 [===============>..............] - ETA: 35s - loss: 0.9801 - categorical_accuracy: 0.6395batch 20\n20/34 [================>.............] - ETA: 32s - loss: 0.9950 - categorical_accuracy: 0.6300batch 21\n21/34 [=================>............] - ETA: 30s - loss: 0.9762 - categorical_accuracy: 0.6357batch 22\n22/34 [==================>...........] - ETA: 28s - loss: 0.9735 - categorical_accuracy: 0.6364batch 23\n23/34 [===================>..........] - ETA: 25s - loss: 0.9631 - categorical_accuracy: 0.6391batch 24\n24/34 [====================>.........] - ETA: 23s - loss: 0.9626 - categorical_accuracy: 0.6354batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.9740 - categorical_accuracy: 0.6360batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 0.9802 - categorical_accuracy: 0.6327batch 27\n27/34 [======================>.......] - ETA: 16s - loss: 0.9702 - categorical_accuracy: 0.6389batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.9636 - categorical_accuracy: 0.6446batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.9638 - categorical_accuracy: 0.6483batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 0.9638 - categorical_accuracy: 0.6433 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.9587 - categorical_accuracy: 0.6468batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.9773 - categorical_accuracy: 0.6375last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.9792 - categorical_accuracy: 0.6364batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.9749 - categorical_accuracy: 0.6380batch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 0\n34/34 [==============================] - 89s 3s/step - loss: 0.9749 - categorical_accuracy: 0.6380 - val_loss: 1.5916 - val_categorical_accuracy: 0.5000\n\nEpoch 00016: saving model to model_init_2022-12-0711_29_12.945522/model-00016-0.97487-0.63801-1.59161-0.50000.h5\nEpoch 17/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.4191 - categorical_accuracy: 0.5000batch 2\n 2/34 [>.............................] - ETA: 1:21 - loss: 1.3254 - categorical_accuracy: 0.5500batch 3\n 3/34 [=>............................] - ETA: 1:18 - loss: 1.1282 - categorical_accuracy: 0.6167batch 4\n 4/34 [==>...........................] - ETA: 1:17 - loss: 1.0401 - categorical_accuracy: 0.6250batch 5\n 5/34 [===>..........................] - ETA: 1:11 - loss: 1.1065 - categorical_accuracy: 0.6100batch 6\n 6/34 [====>.........................] - ETA: 1:07 - loss: 1.1648 - categorical_accuracy: 0.6250batch 7\n 7/34 [=====>........................] - ETA: 1:04 - loss: 1.1060 - categorical_accuracy: 0.6214batch 8\n 8/34 [======>.......................] - ETA: 1:00 - loss: 1.1763 - categorical_accuracy: 0.5938batch 9\n 9/34 [======>.......................] - ETA: 57s - loss: 1.1456 - categorical_accuracy: 0.5944 batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 1.0856 - categorical_accuracy: 0.6150batch 11\n11/34 [========>.....................] - ETA: 51s - loss: 1.0879 - categorical_accuracy: 0.6227batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 1.0976 - categorical_accuracy: 0.6208batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 1.0945 - categorical_accuracy: 0.6269batch 14\n14/34 [===========>..................] - ETA: 44s - loss: 1.1019 - categorical_accuracy: 0.6214batch 15\n15/34 [============>.................] - ETA: 42s - loss: 1.0921 - categorical_accuracy: 0.6233batch 16\n16/34 [=============>................] - ETA: 40s - loss: 1.0859 - categorical_accuracy: 0.6250batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 1.0934 - categorical_accuracy: 0.6324batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 1.0950 - categorical_accuracy: 0.6250batch 19\n19/34 [===============>..............] - ETA: 34s - loss: 1.0877 - categorical_accuracy: 0.6211batch 20\n20/34 [================>.............] - ETA: 31s - loss: 1.0720 - categorical_accuracy: 0.6250batch 21\n21/34 [=================>............] - ETA: 29s - loss: 1.0669 - categorical_accuracy: 0.6286batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 1.0700 - categorical_accuracy: 0.6273batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 1.0571 - categorical_accuracy: 0.6283batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 1.0616 - categorical_accuracy: 0.6292batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 1.0445 - categorical_accuracy: 0.6320batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 1.0417 - categorical_accuracy: 0.6346batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 1.0448 - categorical_accuracy: 0.6333batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 1.0334 - categorical_accuracy: 0.6357batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 1.0125 - categorical_accuracy: 0.6414batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 1.0140 - categorical_accuracy: 0.6433 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.9984 - categorical_accuracy: 0.6500batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.9968 - categorical_accuracy: 0.6484last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.9854 - categorical_accuracy: 0.6500batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.9920 - categorical_accuracy: 0.6471batch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 0\nbatch 1\n34/34 [==============================] - 88s 3s/step - loss: 0.9920 - categorical_accuracy: 0.6471 - val_loss: 1.5093 - val_categorical_accuracy: 0.5000\n\nEpoch 00017: saving model to model_init_2022-12-0711_29_12.945522/model-00017-0.99196-0.64706-1.50932-0.50000.h5\nEpoch 18/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 0.7691 - categorical_accuracy: 0.7000batch 2\n 2/34 [>.............................] - ETA: 1:11 - loss: 0.6676 - categorical_accuracy: 0.7500batch 3\n 3/34 [=>............................] - ETA: 1:12 - loss: 0.8246 - categorical_accuracy: 0.7167batch 4\n 4/34 [==>...........................] - ETA: 1:08 - loss: 0.7990 - categorical_accuracy: 0.7250batch 5\n 5/34 [===>..........................] - ETA: 1:05 - loss: 0.7492 - categorical_accuracy: 0.7400batch 6\n 6/34 [====>.........................] - ETA: 1:01 - loss: 0.7378 - categorical_accuracy: 0.7333batch 7\n 7/34 [=====>........................] - ETA: 1:02 - loss: 0.8175 - categorical_accuracy: 0.7143batch 8\n 8/34 [======>.......................] - ETA: 59s - loss: 0.8001 - categorical_accuracy: 0.7063 batch 9\n 9/34 [======>.......................] - ETA: 57s - loss: 0.8610 - categorical_accuracy: 0.6889batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 0.8728 - categorical_accuracy: 0.6850batch 11\n11/34 [========>.....................] - ETA: 52s - loss: 0.9106 - categorical_accuracy: 0.6727batch 12\n12/34 [=========>....................] - ETA: 50s - loss: 0.9157 - categorical_accuracy: 0.6625batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 0.9000 - categorical_accuracy: 0.6692batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 0.9146 - categorical_accuracy: 0.6536batch 15\n15/34 [============>.................] - ETA: 42s - loss: 0.8915 - categorical_accuracy: 0.6667batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.8761 - categorical_accuracy: 0.6719batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 0.8656 - categorical_accuracy: 0.6735batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 0.8674 - categorical_accuracy: 0.6722batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 0.8783 - categorical_accuracy: 0.6711batch 20\n20/34 [================>.............] - ETA: 31s - loss: 0.8579 - categorical_accuracy: 0.6775batch 21\n21/34 [=================>............] - ETA: 29s - loss: 0.8529 - categorical_accuracy: 0.6762batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 0.8347 - categorical_accuracy: 0.6795batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.8391 - categorical_accuracy: 0.6783batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.8210 - categorical_accuracy: 0.6833batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.8356 - categorical_accuracy: 0.6800batch 26\n26/34 [=====================>........] - ETA: 17s - loss: 0.8446 - categorical_accuracy: 0.6788batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.8514 - categorical_accuracy: 0.6778batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.8691 - categorical_accuracy: 0.6714batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.8694 - categorical_accuracy: 0.6707batch 30\n30/34 [=========================>....] - ETA: 8s - loss: 0.8669 - categorical_accuracy: 0.6750 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.8684 - categorical_accuracy: 0.6726batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.8616 - categorical_accuracy: 0.6766last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.8508 - categorical_accuracy: 0.6803batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.8510 - categorical_accuracy: 0.6802batch 2\nbatch 3\nbatch 4\nbatch 0\nbatch 1\nbatch 2\n34/34 [==============================] - 87s 3s/step - loss: 0.8510 - categorical_accuracy: 0.6802 - val_loss: 1.2962 - val_categorical_accuracy: 0.6000\n\nEpoch 00018: saving model to model_init_2022-12-0711_29_12.945522/model-00018-0.85103-0.68024-1.29619-0.60000.h5\nEpoch 19/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.0678 - categorical_accuracy: 0.7000batch 2\n 2/34 [>.............................] - ETA: 1:05 - loss: 1.1467 - categorical_accuracy: 0.6250batch 3\n 3/34 [=>............................] - ETA: 1:07 - loss: 1.2160 - categorical_accuracy: 0.6000batch 4\n 4/34 [==>...........................] - ETA: 1:04 - loss: 1.1313 - categorical_accuracy: 0.6125batch 5\n 5/34 [===>..........................] - ETA: 1:01 - loss: 1.2464 - categorical_accuracy: 0.5500batch 6\n 6/34 [====>.........................] - ETA: 1:00 - loss: 1.1404 - categorical_accuracy: 0.5750batch 7\n 7/34 [=====>........................] - ETA: 58s - loss: 1.1112 - categorical_accuracy: 0.5929 batch 8\n 8/34 [======>.......................] - ETA: 57s - loss: 1.1848 - categorical_accuracy: 0.5562batch 9\n 9/34 [======>.......................] - ETA: 54s - loss: 1.1613 - categorical_accuracy: 0.5611batch 10\n10/34 [=======>......................] - ETA: 51s - loss: 1.1422 - categorical_accuracy: 0.5750batch 11\n11/34 [========>.....................] - ETA: 50s - loss: 1.1387 - categorical_accuracy: 0.5727batch 12\n12/34 [=========>....................] - ETA: 48s - loss: 1.0974 - categorical_accuracy: 0.5875batch 13\n13/34 [==========>...................] - ETA: 46s - loss: 1.1093 - categorical_accuracy: 0.5962batch 14\n14/34 [===========>..................] - ETA: 43s - loss: 1.0941 - categorical_accuracy: 0.6000batch 15\n15/34 [============>.................] - ETA: 41s - loss: 1.0624 - categorical_accuracy: 0.6067batch 16\n16/34 [=============>................] - ETA: 39s - loss: 1.0138 - categorical_accuracy: 0.6250batch 17\n17/34 [==============>...............] - ETA: 37s - loss: 1.0281 - categorical_accuracy: 0.6265batch 18\n18/34 [==============>...............] - ETA: 35s - loss: 1.0127 - categorical_accuracy: 0.6333batch 19\n19/34 [===============>..............] - ETA: 32s - loss: 1.0212 - categorical_accuracy: 0.6395batch 20\n20/34 [================>.............] - ETA: 30s - loss: 1.0232 - categorical_accuracy: 0.6400batch 21\n21/34 [=================>............] - ETA: 28s - loss: 0.9939 - categorical_accuracy: 0.6476batch 22\n22/34 [==================>...........] - ETA: 26s - loss: 0.9814 - categorical_accuracy: 0.6477batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.9669 - categorical_accuracy: 0.6500batch 24\n24/34 [====================>.........] - ETA: 21s - loss: 0.9793 - categorical_accuracy: 0.6458batch 25\n25/34 [=====================>........] - ETA: 19s - loss: 0.9723 - categorical_accuracy: 0.6440batch 26\n26/34 [=====================>........] - ETA: 17s - loss: 0.9737 - categorical_accuracy: 0.6423batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.9852 - categorical_accuracy: 0.6370batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.9885 - categorical_accuracy: 0.6339batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.9863 - categorical_accuracy: 0.6328batch 30\n30/34 [=========================>....] - ETA: 8s - loss: 0.9759 - categorical_accuracy: 0.6333 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.9800 - categorical_accuracy: 0.6323batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.9803 - categorical_accuracy: 0.6281last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.9803 - categorical_accuracy: 0.6318batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.9761 - categorical_accuracy: 0.6335batch 3\nbatch 4\nbatch 0\nbatch 1\nbatch 2\nbatch 3\n34/34 [==============================] - 87s 3s/step - loss: 0.9761 - categorical_accuracy: 0.6335 - val_loss: 1.4492 - val_categorical_accuracy: 0.5300\n\nEpoch 00019: saving model to model_init_2022-12-0711_29_12.945522/model-00019-0.97613-0.63348-1.44923-0.53000.h5\nEpoch 20/30\nbatch 1\n 1/34 [..............................] - ETA: 27s - loss: 1.4029 - categorical_accuracy: 0.5500batch 2\n 2/34 [>.............................] - ETA: 1:07 - loss: 1.0475 - categorical_accuracy: 0.6250batch 3\n 3/34 [=>............................] - ETA: 1:06 - loss: 1.0528 - categorical_accuracy: 0.5667batch 4\n 4/34 [==>...........................] - ETA: 1:03 - loss: 0.9866 - categorical_accuracy: 0.6125batch 5\n 5/34 [===>..........................] - ETA: 1:01 - loss: 0.9642 - categorical_accuracy: 0.6200batch 6\n 6/34 [====>.........................] - ETA: 1:00 - loss: 0.9697 - categorical_accuracy: 0.6333batch 7\n 7/34 [=====>........................] - ETA: 58s - loss: 0.8992 - categorical_accuracy: 0.6500 batch 8\n 8/34 [======>.......................] - ETA: 56s - loss: 0.8438 - categorical_accuracy: 0.6687batch 9\n 9/34 [======>.......................] - ETA: 54s - loss: 0.8661 - categorical_accuracy: 0.6667batch 10\n10/34 [=======>......................] - ETA: 52s - loss: 0.8786 - categorical_accuracy: 0.6550batch 11\n11/34 [========>.....................] - ETA: 49s - loss: 0.8849 - categorical_accuracy: 0.6545batch 12\n12/34 [=========>....................] - ETA: 47s - loss: 0.9322 - categorical_accuracy: 0.6417batch 13\n13/34 [==========>...................] - ETA: 45s - loss: 0.9653 - categorical_accuracy: 0.6423batch 14\n14/34 [===========>..................] - ETA: 44s - loss: 0.9750 - categorical_accuracy: 0.6500batch 15\n15/34 [============>.................] - ETA: 42s - loss: 0.9653 - categorical_accuracy: 0.6533batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.9668 - categorical_accuracy: 0.6438batch 17\n17/34 [==============>...............] - ETA: 37s - loss: 0.9553 - categorical_accuracy: 0.6471batch 18\n18/34 [==============>...............] - ETA: 35s - loss: 0.9247 - categorical_accuracy: 0.6583batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 0.9132 - categorical_accuracy: 0.6605batch 20\n20/34 [================>.............] - ETA: 31s - loss: 0.9040 - categorical_accuracy: 0.6575batch 21\n21/34 [=================>............] - ETA: 28s - loss: 0.8926 - categorical_accuracy: 0.6571batch 22\n22/34 [==================>...........] - ETA: 26s - loss: 0.8995 - categorical_accuracy: 0.6568batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.8999 - categorical_accuracy: 0.6565batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.8910 - categorical_accuracy: 0.6604batch 25\n25/34 [=====================>........] - ETA: 19s - loss: 0.8988 - categorical_accuracy: 0.6600batch 26\n26/34 [=====================>........] - ETA: 17s - loss: 0.9040 - categorical_accuracy: 0.6577batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.9097 - categorical_accuracy: 0.6556batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.9095 - categorical_accuracy: 0.6589batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.9108 - categorical_accuracy: 0.6517batch 30\n30/34 [=========================>....] - ETA: 8s - loss: 0.9025 - categorical_accuracy: 0.6550 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.8923 - categorical_accuracy: 0.6581batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.9062 - categorical_accuracy: 0.6547last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.9017 - categorical_accuracy: 0.6591batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.9009 - categorical_accuracy: 0.6591batch 4\nbatch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\n34/34 [==============================] - 86s 3s/step - loss: 0.9009 - categorical_accuracy: 0.6591 - val_loss: 1.1541 - val_categorical_accuracy: 0.6400\n\nEpoch 00020: saving model to model_init_2022-12-0711_29_12.945522/model-00020-0.90093-0.65913-1.15406-0.64000.h5\nEpoch 21/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 0.8489 - categorical_accuracy: 0.7000batch 2\n 2/34 [>.............................] - ETA: 1:09 - loss: 0.9131 - categorical_accuracy: 0.6750batch 3\n 3/34 [=>............................] - ETA: 1:08 - loss: 0.8635 - categorical_accuracy: 0.6667batch 4\n 4/34 [==>...........................] - ETA: 1:13 - loss: 0.8524 - categorical_accuracy: 0.6750batch 5\n 5/34 [===>..........................] - ETA: 1:08 - loss: 0.8604 - categorical_accuracy: 0.6800batch 6\n 6/34 [====>.........................] - ETA: 1:05 - loss: 0.9556 - categorical_accuracy: 0.6667batch 7\n 7/34 [=====>........................] - ETA: 1:02 - loss: 0.9448 - categorical_accuracy: 0.6643batch 8\n 8/34 [======>.......................] - ETA: 1:01 - loss: 0.9040 - categorical_accuracy: 0.6812batch 9\n 9/34 [======>.......................] - ETA: 57s - loss: 0.9159 - categorical_accuracy: 0.6778 batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 0.9749 - categorical_accuracy: 0.6650batch 11\n11/34 [========>.....................] - ETA: 52s - loss: 0.9735 - categorical_accuracy: 0.6773batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 0.9461 - categorical_accuracy: 0.6833batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 0.9358 - categorical_accuracy: 0.6808batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 0.9467 - categorical_accuracy: 0.6786batch 15\n15/34 [============>.................] - ETA: 43s - loss: 0.9333 - categorical_accuracy: 0.6800batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.9148 - categorical_accuracy: 0.6812batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 0.9050 - categorical_accuracy: 0.6853batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 0.8967 - categorical_accuracy: 0.6889batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 0.8981 - categorical_accuracy: 0.6921batch 20\n20/34 [================>.............] - ETA: 31s - loss: 0.8908 - categorical_accuracy: 0.6950batch 21\n21/34 [=================>............] - ETA: 29s - loss: 0.8869 - categorical_accuracy: 0.6976batch 22\n22/34 [==================>...........] - ETA: 26s - loss: 0.8896 - categorical_accuracy: 0.7000batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.8902 - categorical_accuracy: 0.6978batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.8843 - categorical_accuracy: 0.7000batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.8747 - categorical_accuracy: 0.7040batch 26\n26/34 [=====================>........] - ETA: 17s - loss: 0.8784 - categorical_accuracy: 0.6981batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.8935 - categorical_accuracy: 0.6926batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.8842 - categorical_accuracy: 0.6929batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.8896 - categorical_accuracy: 0.6931batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 0.8877 - categorical_accuracy: 0.6933 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.8897 - categorical_accuracy: 0.6935batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.8776 - categorical_accuracy: 0.6969last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.8616 - categorical_accuracy: 0.7000batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.8600 - categorical_accuracy: 0.6998batch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 0\n34/34 [==============================] - 88s 3s/step - loss: 0.8600 - categorical_accuracy: 0.6998 - val_loss: 1.3480 - val_categorical_accuracy: 0.5600\n\nEpoch 00021: saving model to model_init_2022-12-0711_29_12.945522/model-00021-0.85995-0.69985-1.34799-0.56000.h5\nEpoch 22/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 0.9134 - categorical_accuracy: 0.6000batch 2\n 2/34 [>.............................] - ETA: 1:09 - loss: 0.8781 - categorical_accuracy: 0.5750batch 3\n 3/34 [=>............................] - ETA: 1:09 - loss: 0.8875 - categorical_accuracy: 0.5500batch 4\n 4/34 [==>...........................] - ETA: 1:08 - loss: 0.9086 - categorical_accuracy: 0.5875batch 5\n 5/34 [===>..........................] - ETA: 1:04 - loss: 0.9077 - categorical_accuracy: 0.5900batch 6\n 6/34 [====>.........................] - ETA: 1:01 - loss: 0.8524 - categorical_accuracy: 0.6167batch 7\n 7/34 [=====>........................] - ETA: 1:01 - loss: 0.8458 - categorical_accuracy: 0.6357batch 8\n 8/34 [======>.......................] - ETA: 59s - loss: 0.8431 - categorical_accuracy: 0.6375 batch 9\n 9/34 [======>.......................] - ETA: 57s - loss: 0.8387 - categorical_accuracy: 0.6500batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 0.8820 - categorical_accuracy: 0.6500batch 11\n11/34 [========>.....................] - ETA: 52s - loss: 0.8705 - categorical_accuracy: 0.6545batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 0.8304 - categorical_accuracy: 0.6708batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 0.8598 - categorical_accuracy: 0.6654batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 0.8907 - categorical_accuracy: 0.6607batch 15\n15/34 [============>.................] - ETA: 42s - loss: 0.9323 - categorical_accuracy: 0.6567batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.9352 - categorical_accuracy: 0.6594batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 0.9148 - categorical_accuracy: 0.6647batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 0.9217 - categorical_accuracy: 0.6667batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 0.9176 - categorical_accuracy: 0.6658batch 20\n20/34 [================>.............] - ETA: 31s - loss: 0.9254 - categorical_accuracy: 0.6625batch 21\n21/34 [=================>............] - ETA: 29s - loss: 0.9368 - categorical_accuracy: 0.6595batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 0.9298 - categorical_accuracy: 0.6568batch 23\n23/34 [===================>..........] - ETA: 25s - loss: 0.9059 - categorical_accuracy: 0.6696batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.8932 - categorical_accuracy: 0.6729batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.8800 - categorical_accuracy: 0.6760batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 0.8629 - categorical_accuracy: 0.6788batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.8799 - categorical_accuracy: 0.6759batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.8815 - categorical_accuracy: 0.6768batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.8711 - categorical_accuracy: 0.6810batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 0.8703 - categorical_accuracy: 0.6800 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.8632 - categorical_accuracy: 0.6806batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.8627 - categorical_accuracy: 0.6766last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.8644 - categorical_accuracy: 0.6758batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.8616 - categorical_accuracy: 0.6772batch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 0\nbatch 1\n34/34 [==============================] - 88s 3s/step - loss: 0.8616 - categorical_accuracy: 0.6772 - val_loss: 1.1511 - val_categorical_accuracy: 0.6300\n\nEpoch 00022: saving model to model_init_2022-12-0711_29_12.945522/model-00022-0.86164-0.67722-1.15114-0.63000.h5\nEpoch 23/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.2176 - categorical_accuracy: 0.6500batch 2\n 2/34 [>.............................] - ETA: 1:05 - loss: 1.1629 - categorical_accuracy: 0.6750batch 3\n 3/34 [=>............................] - ETA: 1:09 - loss: 0.9966 - categorical_accuracy: 0.6667batch 4\n 4/34 [==>...........................] - ETA: 1:09 - loss: 0.9580 - categorical_accuracy: 0.6875batch 5\n 5/34 [===>..........................] - ETA: 1:06 - loss: 0.9729 - categorical_accuracy: 0.7000batch 6\n 6/34 [====>.........................] - ETA: 1:03 - loss: 0.9392 - categorical_accuracy: 0.7000batch 7\n 7/34 [=====>........................] - ETA: 1:00 - loss: 0.9219 - categorical_accuracy: 0.6857batch 8\n 8/34 [======>.......................] - ETA: 58s - loss: 0.8947 - categorical_accuracy: 0.7000 batch 9\n 9/34 [======>.......................] - ETA: 56s - loss: 0.8688 - categorical_accuracy: 0.7111batch 10\n10/34 [=======>......................] - ETA: 55s - loss: 0.8428 - categorical_accuracy: 0.7150batch 11\n11/34 [========>.....................] - ETA: 52s - loss: 0.8699 - categorical_accuracy: 0.7000batch 12\n12/34 [=========>....................] - ETA: 50s - loss: 0.8848 - categorical_accuracy: 0.6833batch 13\n13/34 [==========>...................] - ETA: 48s - loss: 0.9010 - categorical_accuracy: 0.6846batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 0.8757 - categorical_accuracy: 0.6964batch 15\n15/34 [============>.................] - ETA: 43s - loss: 0.8844 - categorical_accuracy: 0.6900batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.8886 - categorical_accuracy: 0.6875batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 0.8727 - categorical_accuracy: 0.6912batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 0.8610 - categorical_accuracy: 0.6889batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 0.8782 - categorical_accuracy: 0.6842batch 20\n20/34 [================>.............] - ETA: 31s - loss: 0.8809 - categorical_accuracy: 0.6800batch 21\n21/34 [=================>............] - ETA: 29s - loss: 0.8980 - categorical_accuracy: 0.6690batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 0.8857 - categorical_accuracy: 0.6750batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.8657 - categorical_accuracy: 0.6826batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.8642 - categorical_accuracy: 0.6812batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.8650 - categorical_accuracy: 0.6800batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 0.8476 - categorical_accuracy: 0.6846batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.8500 - categorical_accuracy: 0.6833batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.8487 - categorical_accuracy: 0.6821batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.8550 - categorical_accuracy: 0.6793batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 0.8581 - categorical_accuracy: 0.6783 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.8575 - categorical_accuracy: 0.6790batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.8517 - categorical_accuracy: 0.6828last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.8421 - categorical_accuracy: 0.6879batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.8433 - categorical_accuracy: 0.6878batch 2\nbatch 3\nbatch 4\nbatch 0\nbatch 1\nbatch 2\n34/34 [==============================] - 88s 3s/step - loss: 0.8433 - categorical_accuracy: 0.6878 - val_loss: 1.0663 - val_categorical_accuracy: 0.6600\n\nEpoch 00023: saving model to model_init_2022-12-0711_29_12.945522/model-00023-0.84327-0.68778-1.06635-0.66000.h5\nEpoch 24/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.0652 - categorical_accuracy: 0.4000batch 2\n 2/34 [>.............................] - ETA: 1:04 - loss: 1.1030 - categorical_accuracy: 0.4500batch 3\n 3/34 [=>............................] - ETA: 1:03 - loss: 1.0916 - categorical_accuracy: 0.5167batch 4\n 4/34 [==>...........................] - ETA: 1:05 - loss: 1.0802 - categorical_accuracy: 0.5375batch 5\n 5/34 [===>..........................] - ETA: 1:03 - loss: 1.0587 - categorical_accuracy: 0.5600batch 6\n 6/34 [====>.........................] - ETA: 1:02 - loss: 1.0198 - categorical_accuracy: 0.5833batch 7\n 7/34 [=====>........................] - ETA: 59s - loss: 0.9942 - categorical_accuracy: 0.6000 batch 8\n 8/34 [======>.......................] - ETA: 57s - loss: 1.0149 - categorical_accuracy: 0.6187batch 9\n 9/34 [======>.......................] - ETA: 55s - loss: 0.9606 - categorical_accuracy: 0.6389batch 10\n10/34 [=======>......................] - ETA: 52s - loss: 0.9375 - categorical_accuracy: 0.6550batch 11\n11/34 [========>.....................] - ETA: 50s - loss: 0.8991 - categorical_accuracy: 0.6727batch 12\n12/34 [=========>....................] - ETA: 48s - loss: 0.9315 - categorical_accuracy: 0.6625batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 0.9072 - categorical_accuracy: 0.6731batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 0.9235 - categorical_accuracy: 0.6714batch 15\n15/34 [============>.................] - ETA: 42s - loss: 0.9130 - categorical_accuracy: 0.6767batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.8870 - categorical_accuracy: 0.6812batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 0.8638 - categorical_accuracy: 0.6912batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 0.8428 - categorical_accuracy: 0.7000batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 0.8426 - categorical_accuracy: 0.7026batch 20\n20/34 [================>.............] - ETA: 31s - loss: 0.8585 - categorical_accuracy: 0.6950batch 21\n21/34 [=================>............] - ETA: 28s - loss: 0.8609 - categorical_accuracy: 0.6929batch 22\n22/34 [==================>...........] - ETA: 26s - loss: 0.8753 - categorical_accuracy: 0.6909batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.8723 - categorical_accuracy: 0.6891batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.8718 - categorical_accuracy: 0.6875batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.8549 - categorical_accuracy: 0.6940batch 26\n26/34 [=====================>........] - ETA: 17s - loss: 0.8653 - categorical_accuracy: 0.6904batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.8562 - categorical_accuracy: 0.6926batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.8736 - categorical_accuracy: 0.6857batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.8740 - categorical_accuracy: 0.6862batch 30\n30/34 [=========================>....] - ETA: 8s - loss: 0.8676 - categorical_accuracy: 0.6883 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.8731 - categorical_accuracy: 0.6855batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.8851 - categorical_accuracy: 0.6828last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.8795 - categorical_accuracy: 0.6848batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.8791 - categorical_accuracy: 0.6848batch 3\nbatch 4\nbatch 0\nbatch 1\nbatch 2\nbatch 3\n34/34 [==============================] - 88s 3s/step - loss: 0.8791 - categorical_accuracy: 0.6848 - val_loss: 0.9155 - val_categorical_accuracy: 0.6900\n\nEpoch 00024: saving model to model_init_2022-12-0711_29_12.945522/model-00024-0.87912-0.68477-0.91550-0.69000.h5\nEpoch 25/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 0.8779 - categorical_accuracy: 0.7500batch 2\n 2/34 [>.............................] - ETA: 1:26 - loss: 0.7647 - categorical_accuracy: 0.7750batch 3\n 3/34 [=>............................] - ETA: 1:17 - loss: 0.8519 - categorical_accuracy: 0.7500batch 4\n 4/34 [==>...........................] - ETA: 1:11 - loss: 0.8659 - categorical_accuracy: 0.7125batch 5\n 5/34 [===>..........................] - ETA: 1:07 - loss: 0.7998 - categorical_accuracy: 0.7000batch 6\n 6/34 [====>.........................] - ETA: 1:05 - loss: 0.8118 - categorical_accuracy: 0.7000batch 7\n 7/34 [=====>........................] - ETA: 1:02 - loss: 0.8791 - categorical_accuracy: 0.7000batch 8\n 8/34 [======>.......................] - ETA: 1:00 - loss: 0.8570 - categorical_accuracy: 0.7188batch 9\n 9/34 [======>.......................] - ETA: 57s - loss: 0.8441 - categorical_accuracy: 0.7222 batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 0.9091 - categorical_accuracy: 0.6950batch 11\n11/34 [========>.....................] - ETA: 52s - loss: 0.9075 - categorical_accuracy: 0.6955batch 12\n12/34 [=========>....................] - ETA: 50s - loss: 0.8889 - categorical_accuracy: 0.7042batch 13\n13/34 [==========>...................] - ETA: 48s - loss: 0.8578 - categorical_accuracy: 0.7077batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 0.8848 - categorical_accuracy: 0.6964batch 15\n15/34 [============>.................] - ETA: 44s - loss: 0.8693 - categorical_accuracy: 0.6967batch 16\n16/34 [=============>................] - ETA: 41s - loss: 0.8666 - categorical_accuracy: 0.6906batch 17\n17/34 [==============>...............] - ETA: 39s - loss: 0.8580 - categorical_accuracy: 0.6941batch 18\n18/34 [==============>...............] - ETA: 37s - loss: 0.8529 - categorical_accuracy: 0.6917batch 19\n19/34 [===============>..............] - ETA: 35s - loss: 0.8452 - categorical_accuracy: 0.6947batch 20\n20/34 [================>.............] - ETA: 32s - loss: 0.8465 - categorical_accuracy: 0.6950batch 21\n21/34 [=================>............] - ETA: 30s - loss: 0.8269 - categorical_accuracy: 0.7048batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 0.8522 - categorical_accuracy: 0.6977batch 23\n23/34 [===================>..........] - ETA: 25s - loss: 0.8707 - categorical_accuracy: 0.6935batch 24\n24/34 [====================>.........] - ETA: 23s - loss: 0.8665 - categorical_accuracy: 0.6938batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.8529 - categorical_accuracy: 0.7000batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 0.8400 - categorical_accuracy: 0.7000batch 27\n27/34 [======================>.......] - ETA: 16s - loss: 0.8435 - categorical_accuracy: 0.6981batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.8321 - categorical_accuracy: 0.7054batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.8411 - categorical_accuracy: 0.7000batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 0.8465 - categorical_accuracy: 0.7000 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.8438 - categorical_accuracy: 0.7016batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.8429 - categorical_accuracy: 0.7000last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.8403 - categorical_accuracy: 0.6985batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.8423 - categorical_accuracy: 0.6983batch 4\nbatch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\n34/34 [==============================] - 89s 3s/step - loss: 0.8423 - categorical_accuracy: 0.6983 - val_loss: 0.9685 - val_categorical_accuracy: 0.6900\n\nEpoch 00025: saving model to model_init_2022-12-0711_29_12.945522/model-00025-0.84233-0.69834-0.96851-0.69000.h5\nEpoch 26/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 0.5344 - categorical_accuracy: 0.7000batch 2\n 2/34 [>.............................] - ETA: 1:07 - loss: 0.7681 - categorical_accuracy: 0.7000batch 3\n 3/34 [=>............................] - ETA: 1:11 - loss: 0.8865 - categorical_accuracy: 0.6833batch 4\n 4/34 [==>...........................] - ETA: 1:10 - loss: 0.7421 - categorical_accuracy: 0.7250batch 5\n 5/34 [===>..........................] - ETA: 1:07 - loss: 0.8438 - categorical_accuracy: 0.6900batch 6\n 6/34 [====>.........................] - ETA: 1:03 - loss: 0.8730 - categorical_accuracy: 0.6750batch 7\n 7/34 [=====>........................] - ETA: 1:00 - loss: 0.8050 - categorical_accuracy: 0.7071batch 8\n 8/34 [======>.......................] - ETA: 59s - loss: 0.8024 - categorical_accuracy: 0.7125 batch 9\n 9/34 [======>.......................] - ETA: 56s - loss: 0.8204 - categorical_accuracy: 0.7111batch 10\n10/34 [=======>......................] - ETA: 53s - loss: 0.8301 - categorical_accuracy: 0.7000batch 11\n11/34 [========>.....................] - ETA: 51s - loss: 0.8527 - categorical_accuracy: 0.6818batch 12\n12/34 [=========>....................] - ETA: 48s - loss: 0.8588 - categorical_accuracy: 0.6833batch 13\n13/34 [==========>...................] - ETA: 46s - loss: 0.8521 - categorical_accuracy: 0.6885batch 14\n14/34 [===========>..................] - ETA: 44s - loss: 0.8598 - categorical_accuracy: 0.6679batch 15\n15/34 [============>.................] - ETA: 42s - loss: 0.8468 - categorical_accuracy: 0.6733batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.8743 - categorical_accuracy: 0.6687batch 17\n17/34 [==============>...............] - ETA: 37s - loss: 0.8796 - categorical_accuracy: 0.6588batch 18\n18/34 [==============>...............] - ETA: 35s - loss: 0.8811 - categorical_accuracy: 0.6528batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 0.8842 - categorical_accuracy: 0.6526batch 20\n20/34 [================>.............] - ETA: 31s - loss: 0.8894 - categorical_accuracy: 0.6525batch 21\n21/34 [=================>............] - ETA: 28s - loss: 0.8796 - categorical_accuracy: 0.6571batch 22\n22/34 [==================>...........] - ETA: 26s - loss: 0.8726 - categorical_accuracy: 0.6568batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.8660 - categorical_accuracy: 0.6609batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.8600 - categorical_accuracy: 0.6583batch 25\n25/34 [=====================>........] - ETA: 19s - loss: 0.8441 - categorical_accuracy: 0.6640batch 26\n26/34 [=====================>........] - ETA: 17s - loss: 0.8555 - categorical_accuracy: 0.6654batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.8628 - categorical_accuracy: 0.6611batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.8525 - categorical_accuracy: 0.6679batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.8548 - categorical_accuracy: 0.6724batch 30\n30/34 [=========================>....] - ETA: 8s - loss: 0.8703 - categorical_accuracy: 0.6733 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.8640 - categorical_accuracy: 0.6742batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.8619 - categorical_accuracy: 0.6734last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.8663 - categorical_accuracy: 0.6727batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.8650 - categorical_accuracy: 0.6727batch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 0\n34/34 [==============================] - 87s 3s/step - loss: 0.8650 - categorical_accuracy: 0.6727 - val_loss: 0.9925 - val_categorical_accuracy: 0.6500\n\nEpoch 00026: saving model to model_init_2022-12-0711_29_12.945522/model-00026-0.86498-0.67270-0.99250-0.65000.h5\nEpoch 27/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.1989 - categorical_accuracy: 0.7000batch 2\n 2/34 [>.............................] - ETA: 1:08 - loss: 0.9755 - categorical_accuracy: 0.7250batch 3\n 3/34 [=>............................] - ETA: 1:10 - loss: 0.9225 - categorical_accuracy: 0.7000batch 4\n 4/34 [==>...........................] - ETA: 1:07 - loss: 0.8612 - categorical_accuracy: 0.7125batch 5\n 5/34 [===>..........................] - ETA: 1:04 - loss: 0.8275 - categorical_accuracy: 0.7100batch 6\n 6/34 [====>.........................] - ETA: 1:02 - loss: 0.8150 - categorical_accuracy: 0.7083batch 7\n 7/34 [=====>........................] - ETA: 1:01 - loss: 0.8380 - categorical_accuracy: 0.7000batch 8\n 8/34 [======>.......................] - ETA: 59s - loss: 0.8303 - categorical_accuracy: 0.7000 batch 9\n 9/34 [======>.......................] - ETA: 57s - loss: 0.8957 - categorical_accuracy: 0.6667batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 0.9300 - categorical_accuracy: 0.6550batch 11\n11/34 [========>.....................] - ETA: 51s - loss: 0.9033 - categorical_accuracy: 0.6591batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 0.9281 - categorical_accuracy: 0.6625batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 0.9014 - categorical_accuracy: 0.6654batch 14\n14/34 [===========>..................] - ETA: 45s - loss: 0.8892 - categorical_accuracy: 0.6750batch 15\n15/34 [============>.................] - ETA: 43s - loss: 0.8734 - categorical_accuracy: 0.6767batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.8438 - categorical_accuracy: 0.6844batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 0.8404 - categorical_accuracy: 0.6882batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 0.8407 - categorical_accuracy: 0.6861batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 0.8329 - categorical_accuracy: 0.6921batch 20\n20/34 [================>.............] - ETA: 31s - loss: 0.8613 - categorical_accuracy: 0.6875batch 21\n21/34 [=================>............] - ETA: 29s - loss: 0.8337 - categorical_accuracy: 0.6952batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 0.8274 - categorical_accuracy: 0.6955batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.8267 - categorical_accuracy: 0.6957batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.8458 - categorical_accuracy: 0.6917batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.8411 - categorical_accuracy: 0.6920batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 0.8386 - categorical_accuracy: 0.6923batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.8357 - categorical_accuracy: 0.6907batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.8407 - categorical_accuracy: 0.6893batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.8308 - categorical_accuracy: 0.6931batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 0.8203 - categorical_accuracy: 0.6967 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.8072 - categorical_accuracy: 0.6968batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.8210 - categorical_accuracy: 0.6969last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.8355 - categorical_accuracy: 0.6924batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.8339 - categorical_accuracy: 0.6923batch 1\nbatch 2\nbatch 3\nbatch 4\nbatch 0\nbatch 1\n34/34 [==============================] - 88s 3s/step - loss: 0.8339 - categorical_accuracy: 0.6923 - val_loss: 1.0218 - val_categorical_accuracy: 0.6800\n\nEpoch 00027: saving model to model_init_2022-12-0711_29_12.945522/model-00027-0.83386-0.69231-1.02182-0.68000.h5\nEpoch 28/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 1.2285 - categorical_accuracy: 0.5000batch 2\n 2/34 [>.............................] - ETA: 1:10 - loss: 0.8277 - categorical_accuracy: 0.6500batch 3\n 3/34 [=>............................] - ETA: 1:09 - loss: 0.8355 - categorical_accuracy: 0.6500batch 4\n 4/34 [==>...........................] - ETA: 1:06 - loss: 0.8065 - categorical_accuracy: 0.6500batch 5\n 5/34 [===>..........................] - ETA: 1:03 - loss: 0.8242 - categorical_accuracy: 0.6600batch 6\n 6/34 [====>.........................] - ETA: 1:02 - loss: 0.8674 - categorical_accuracy: 0.6583batch 7\n 7/34 [=====>........................] - ETA: 59s - loss: 0.9131 - categorical_accuracy: 0.6643 batch 8\n 8/34 [======>.......................] - ETA: 58s - loss: 0.9182 - categorical_accuracy: 0.6625batch 9\n 9/34 [======>.......................] - ETA: 56s - loss: 0.8985 - categorical_accuracy: 0.6722batch 10\n10/34 [=======>......................] - ETA: 54s - loss: 0.9116 - categorical_accuracy: 0.6700batch 11\n11/34 [========>.....................] - ETA: 51s - loss: 0.8897 - categorical_accuracy: 0.6682batch 12\n12/34 [=========>....................] - ETA: 49s - loss: 0.8618 - categorical_accuracy: 0.6792batch 13\n13/34 [==========>...................] - ETA: 47s - loss: 0.8618 - categorical_accuracy: 0.6769batch 14\n14/34 [===========>..................] - ETA: 44s - loss: 0.8790 - categorical_accuracy: 0.6714batch 15\n15/34 [============>.................] - ETA: 42s - loss: 0.8912 - categorical_accuracy: 0.6667batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.9012 - categorical_accuracy: 0.6625batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 0.8675 - categorical_accuracy: 0.6735batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 0.8573 - categorical_accuracy: 0.6806batch 19\n19/34 [===============>..............] - ETA: 34s - loss: 0.8648 - categorical_accuracy: 0.6789batch 20\n20/34 [================>.............] - ETA: 31s - loss: 0.8539 - categorical_accuracy: 0.6800batch 21\n21/34 [=================>............] - ETA: 29s - loss: 0.8748 - categorical_accuracy: 0.6786batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 0.8710 - categorical_accuracy: 0.6773batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.8612 - categorical_accuracy: 0.6783batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.8636 - categorical_accuracy: 0.6792batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.8745 - categorical_accuracy: 0.6780batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 0.8561 - categorical_accuracy: 0.6827batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.8560 - categorical_accuracy: 0.6833batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.8537 - categorical_accuracy: 0.6875batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.8536 - categorical_accuracy: 0.6828batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 0.8594 - categorical_accuracy: 0.6850 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.8504 - categorical_accuracy: 0.6871batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.8533 - categorical_accuracy: 0.6844last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.8459 - categorical_accuracy: 0.6864batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.8430 - categorical_accuracy: 0.6878batch 2\nbatch 3\nbatch 4\nbatch 0\nbatch 1\nbatch 2\n34/34 [==============================] - 87s 3s/step - loss: 0.8430 - categorical_accuracy: 0.6878 - val_loss: 1.0882 - val_categorical_accuracy: 0.6600\n\nEpoch 00028: saving model to model_init_2022-12-0711_29_12.945522/model-00028-0.84295-0.68778-1.08823-0.66000.h5\nEpoch 29/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 0.3853 - categorical_accuracy: 0.8500batch 2\n 2/34 [>.............................] - ETA: 1:05 - loss: 0.6370 - categorical_accuracy: 0.7000batch 3\n 3/34 [=>............................] - ETA: 1:06 - loss: 0.6703 - categorical_accuracy: 0.7333batch 4\n 4/34 [==>...........................] - ETA: 1:04 - loss: 0.8792 - categorical_accuracy: 0.6875batch 5\n 5/34 [===>..........................] - ETA: 1:03 - loss: 0.8991 - categorical_accuracy: 0.7000batch 6\n 6/34 [====>.........................] - ETA: 1:00 - loss: 0.9662 - categorical_accuracy: 0.6750batch 7\n 7/34 [=====>........................] - ETA: 59s - loss: 0.9625 - categorical_accuracy: 0.6571 batch 8\n 8/34 [======>.......................] - ETA: 57s - loss: 0.9479 - categorical_accuracy: 0.6625batch 9\n 9/34 [======>.......................] - ETA: 55s - loss: 0.9169 - categorical_accuracy: 0.6722batch 10\n10/34 [=======>......................] - ETA: 53s - loss: 0.8685 - categorical_accuracy: 0.6950batch 11\n11/34 [========>.....................] - ETA: 50s - loss: 0.8734 - categorical_accuracy: 0.6955batch 12\n12/34 [=========>....................] - ETA: 48s - loss: 0.8442 - categorical_accuracy: 0.7083batch 13\n13/34 [==========>...................] - ETA: 46s - loss: 0.8482 - categorical_accuracy: 0.7115batch 14\n14/34 [===========>..................] - ETA: 44s - loss: 0.8335 - categorical_accuracy: 0.7143batch 15\n15/34 [============>.................] - ETA: 42s - loss: 0.8321 - categorical_accuracy: 0.7100batch 16\n16/34 [=============>................] - ETA: 40s - loss: 0.8203 - categorical_accuracy: 0.7094batch 17\n17/34 [==============>...............] - ETA: 38s - loss: 0.8265 - categorical_accuracy: 0.7029batch 18\n18/34 [==============>...............] - ETA: 36s - loss: 0.8179 - categorical_accuracy: 0.7056batch 19\n19/34 [===============>..............] - ETA: 33s - loss: 0.8258 - categorical_accuracy: 0.7053batch 20\n20/34 [================>.............] - ETA: 31s - loss: 0.8051 - categorical_accuracy: 0.7075batch 21\n21/34 [=================>............] - ETA: 29s - loss: 0.8129 - categorical_accuracy: 0.7024batch 22\n22/34 [==================>...........] - ETA: 26s - loss: 0.8144 - categorical_accuracy: 0.7000batch 23\n23/34 [===================>..........] - ETA: 24s - loss: 0.8126 - categorical_accuracy: 0.7022batch 24\n24/34 [====================>.........] - ETA: 22s - loss: 0.7972 - categorical_accuracy: 0.7042batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.7883 - categorical_accuracy: 0.7080batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 0.7824 - categorical_accuracy: 0.7115batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.7835 - categorical_accuracy: 0.7130batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.7896 - categorical_accuracy: 0.7071batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.7920 - categorical_accuracy: 0.7034batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 0.7832 - categorical_accuracy: 0.7083 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.7870 - categorical_accuracy: 0.7048batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.7807 - categorical_accuracy: 0.7047last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.7682 - categorical_accuracy: 0.7091batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.7699 - categorical_accuracy: 0.7074batch 3\nbatch 4\nbatch 0\nbatch 1\nbatch 2\nbatch 3\n34/34 [==============================] - 87s 3s/step - loss: 0.7699 - categorical_accuracy: 0.7074 - val_loss: 1.0887 - val_categorical_accuracy: 0.6500\n\nEpoch 00029: saving model to model_init_2022-12-0711_29_12.945522/model-00029-0.76990-0.70739-1.08872-0.65000.h5\nEpoch 30/30\nbatch 1\n 1/34 [..............................] - ETA: 26s - loss: 0.6506 - categorical_accuracy: 0.8000batch 2\n 2/34 [>.............................] - ETA: 1:20 - loss: 0.6939 - categorical_accuracy: 0.8000batch 3\n 3/34 [=>............................] - ETA: 1:22 - loss: 0.7375 - categorical_accuracy: 0.7667batch 4\n 4/34 [==>...........................] - ETA: 1:16 - loss: 0.7917 - categorical_accuracy: 0.7250batch 5\n 5/34 [===>..........................] - ETA: 1:10 - loss: 0.9196 - categorical_accuracy: 0.7000batch 6\n 6/34 [====>.........................] - ETA: 1:06 - loss: 0.9742 - categorical_accuracy: 0.6583batch 7\n 7/34 [=====>........................] - ETA: 1:03 - loss: 0.9708 - categorical_accuracy: 0.6643batch 8\n 8/34 [======>.......................] - ETA: 1:01 - loss: 0.9677 - categorical_accuracy: 0.6500batch 9\n 9/34 [======>.......................] - ETA: 58s - loss: 0.9279 - categorical_accuracy: 0.6611 batch 10\n10/34 [=======>......................] - ETA: 56s - loss: 0.9057 - categorical_accuracy: 0.6700batch 11\n11/34 [========>.....................] - ETA: 53s - loss: 0.9127 - categorical_accuracy: 0.6727batch 12\n12/34 [=========>....................] - ETA: 51s - loss: 0.8971 - categorical_accuracy: 0.6750batch 13\n13/34 [==========>...................] - ETA: 48s - loss: 0.8866 - categorical_accuracy: 0.6769batch 14\n14/34 [===========>..................] - ETA: 46s - loss: 0.8785 - categorical_accuracy: 0.6786batch 15\n15/34 [============>.................] - ETA: 43s - loss: 0.8722 - categorical_accuracy: 0.6800batch 16\n16/34 [=============>................] - ETA: 41s - loss: 0.8447 - categorical_accuracy: 0.6938batch 17\n17/34 [==============>...............] - ETA: 39s - loss: 0.8766 - categorical_accuracy: 0.6853batch 18\n18/34 [==============>...............] - ETA: 37s - loss: 0.8672 - categorical_accuracy: 0.6889batch 19\n19/34 [===============>..............] - ETA: 34s - loss: 0.9029 - categorical_accuracy: 0.6789batch 20\n20/34 [================>.............] - ETA: 32s - loss: 0.9034 - categorical_accuracy: 0.6775batch 21\n21/34 [=================>............] - ETA: 29s - loss: 0.8919 - categorical_accuracy: 0.6833batch 22\n22/34 [==================>...........] - ETA: 27s - loss: 0.8713 - categorical_accuracy: 0.6909batch 23\n23/34 [===================>..........] - ETA: 25s - loss: 0.8798 - categorical_accuracy: 0.6891batch 24\n24/34 [====================>.........] - ETA: 23s - loss: 0.8998 - categorical_accuracy: 0.6854batch 25\n25/34 [=====================>........] - ETA: 20s - loss: 0.9028 - categorical_accuracy: 0.6840batch 26\n26/34 [=====================>........] - ETA: 18s - loss: 0.8844 - categorical_accuracy: 0.6885batch 27\n27/34 [======================>.......] - ETA: 15s - loss: 0.8704 - categorical_accuracy: 0.6889batch 28\n28/34 [=======================>......] - ETA: 13s - loss: 0.8631 - categorical_accuracy: 0.6911batch 29\n29/34 [========================>.....] - ETA: 11s - loss: 0.8540 - categorical_accuracy: 0.6931batch 30\n30/34 [=========================>....] - ETA: 9s - loss: 0.8486 - categorical_accuracy: 0.6933 batch 31\n31/34 [==========================>...] - ETA: 6s - loss: 0.8553 - categorical_accuracy: 0.6919batch 32\n32/34 [===========================>..] - ETA: 4s - loss: 0.8486 - categorical_accuracy: 0.6906last batch 3\nnum_batches 33\n33/34 [============================>.] - ETA: 2s - loss: 0.8509 - categorical_accuracy: 0.6909batch 0\n34/34 [==============================] - ETA: 0s - loss: 0.8529 - categorical_accuracy: 0.6893batch 4\nbatch 0\nbatch 1\nbatch 2\nbatch 3\nbatch 4\n34/34 [==============================] - 88s 3s/step - loss: 0.8529 - categorical_accuracy: 0.6893 - val_loss: 1.1233 - val_categorical_accuracy: 0.6700\n\nEpoch 00030: saving model to model_init_2022-12-0711_29_12.945522/model-00030-0.85290-0.68929-1.12326-0.67000.h5\n","output_type":"stream"},{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fbdcf158f90>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}